[{"Media":"","Paper ID":"10","Paper Title":"Tweakable","Abstract":"In this paper, I describe some of the core features of Tweakable, a new interactive algorithmic music system.Tweakable is a web-based visual programming system (VPS) designed to lower the barrier of entry for creating algorithmic music, while still offering vast possibilities for experimentation.From a palette of components, users can quickly design an algorithmic system, and expose parameters through a user interface that enable the algorithm to be ‘tweaked’ in real time.","Author Names":"Julian Woodward (Visual Systems Ltd)*","Track Name":"Demo","Files":"WAC - tweakable - rev.pdf (489273 bytes)","Pages":""},{"Media":"","Paper ID":"13","Paper Title":"Sounds Aware","Abstract":"Sounds Aware is a web application that runs on a smartphone and uses machine learning to detect human-made sound (anthrophony) and masks it with ambient music as a user walks around their environment. A study was completed to determine if this app is an effective means of shifting a user's attention away from anthrophony and to biological (biophony) and geophysical (geophony) sounds while walking and encouraging environmental awareness. Though the model is pre-trained with the author's local environmental sounds, the user can train the model further on their unique soundscape so that each user gets a personalized experience. After the training process, the user can listen to ambient music based on traits of the surrounding anthrophony. If the app senses less anthrophony and more biophony or geophony, then the music fades away, bringing the user's attention to the anthrophony.","Author Names":"Tate Carson (Louisiana State University)*","Track Name":"Demo","Files":"WAC_2019___Demo_CameraReady.pdf (191466 bytes)","Pages":""},{"Media":"","Paper ID":"17","Paper Title":"GANHarp","Abstract":"We present GANHarp, an experimental browser-based musical instrument powered by AI-generated timbres.GANHarp is a musical instrument whose timbres are entirely generated by a Generative Adversarial Network (GAN), and that allows the player to interpolate between these timbres in real time – think of morphing between the sound of a violin and the sound of a marimba while you are playing.We draw inspiration from wavetable synthesizers such as Serum, and the idea of visual latent space interpolation, and provide a novel user interface combining these two approaches.The user interface provides a real time visualization of the spectrum of the sound you are playing, which also acts as a control surface for morphing the sound. The morphing can also be done using a MIDI controller using pitch bend, or automated using LFOs. Additionally, a standard on-screen keyboard and MIDI keyboard input is included.GANHarp is powered by the GANSynth model from Google Magenta, and the Magenta.js JavaScript interface for said model. It uses AudioWorklets for real time sample accurate wavetable lookup, and WebGL for the 3D visualization.","Author Names":"Tero Parviainen (Counterpoint)*; Samuel Diggins (Counterpoint)","Track Name":"Demo","Files":"","Pages":""},{"Media":"","Paper ID":"20","Paper Title":"Cassettes - An online audio editor","Abstract":"Cassettes is an easy-to-use online audio editor. You can record, add audio files, select, cut, copy, paste, glue, do automation, add audio effects and download selected area as a mixed audio file. https://cassettes.herokuapp.com/","Author Names":"Xingxing Yang (/)*; Jatin Chowdhury (CCRMA)","Track Name":"Demo","Files":"WAC Paper-Cassettes.pdf (268027 bytes)","Pages":""},{"Media":"","Paper ID":"21","Paper Title":"Synth Kitchen","Abstract":"Synth Kitchen leverages the Web Audio API and Web MIDI API to bring interactive modular synthesis to the web. The goal of this project is to make modular synthesis cheap and accessible to anyone with a modern browser.","Author Names":"Spencer Rudnick (Ableton)*","Track Name":"Demo","Files":"Synth Kitchen Submission - WAC19.pdf (281625 bytes)","Pages":""},{"Media":"","Paper ID":"23","Paper Title":"moodplay.github.io: an online collaborative music player","Abstract":"In this demo, we present an online music streaming system that allows users to collaboratively choose music by mood, but also personalise the experience by creating private parties where users can control who to invite to join the party and in which tracks can be shared with other participants. The music is automatically mixed by an auto-DJ module that models various DJ-ing styles using content-based audio features that represent musical parameters such as tempo, beats, bars, keys, instrumentation and volume.","Author Names":"Alo Allik (Queen Mary University of London)*; Florian Thalmann (Queen Mary University of London); Cornelia Metzig (Queen Mary University of London)","Track Name":"Demo","Files":"wac2019_moodplay_demo.pdf (1062487 bytes)","Pages":""},{"Media":"","Paper ID":"28","Paper Title":"Real-Time Formant Tracking and Visualization using Linear Predictive Coding","Abstract":"I present a real-time speech visualization tool built with Web Audio API. The system takes an input audio stream from the microphone, then uses Linear Predictive Coding (LPC) on input buffers to determine the locations of formants F1 and F2. The formants of the current audio buffer are plotted on a 2D graph, and compared with the F1, F2 averages of 12 different vowels that Hillenbrand et al. collected from a sample a speakers.  The plot is continuously updated to reflect the formant locations of the most recent input frame.  Users can gauge how accurately they are pronouncing a vowel from the distance from the current audio buffer’s formant location to that of the phonemes from Hillenbrand.  This application shows the potential to become a useful language pedagogy tool.","Author Names":"Bernard Wang (CCRMA)*","Track Name":"Demo","Files":"","Pages":""},{"Media":"","Paper ID":"32","Paper Title":"Develop WebAudio Plugins in a Web Browser","Abstract":"We propose to demo an online IDE based around the FAUST DSP audio language [1], that includes a source code editor, embedded compiler and GUI editor allowing to directly test, generate and deploy WebAudio Plugins (WAP).","Author Names":"Michel Buffa (Université Côte d’Azur, CNRS, INRIA)*; Stéphane Letz (Grame); Jerome Lebrun (CNRS); Yann Orlarey (GRAME); Romain Michon (Grame: Centre National de Création Musicale); Dominique Fober (GRAME); Shihong Ren (GRAME); ElMehdi Aamari (I3S)","Track Name":"Demo","Files":"WAC 2019 DEMO _ Develop WebAudio Plugins in a web browser (3).pdf (1547462 bytes)","Pages":""},{"Media":"","Paper ID":"","Paper Title":"","Abstract":"","Author Names":"","Track Name":"","Files":"","Pages":""}]