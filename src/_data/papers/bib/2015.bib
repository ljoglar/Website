@InProceedings{2015_24,
author    = {Pike, Chris and Taylour, Peter and Melchior, Frank},
title     = {Delivering Object-Based 3D Audio Using The Web Audio API And The Audio Definition Model},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {2--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents an application that demonstrates object-based 3D audio rendering in the web browser using the Web Audio API. The application loads audio files containing object-based meta-data and provides head-tracked dynamic binaural rendering of the content to create an immersive 3D audio experience for headphone listeners. The user can interact with the rendering by muting individual audio objects and switching between the binaural rendering mode and conventional stereo rendering. This application demonstrates the future of broadcast sound experiences over the web, where immersive content is rendered on the client and can be adapted to listener context, as page layout is adapted to device context today with responsive design.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_24.pdf:pdf},
isbn      = {0199537992},
issn      = {2663-5844},
keywords  = {audio definition,object-based broadcasting,web audio api},
type      = {Paper},
url       = {https://wac.ircam.fr/pdf/wac15_submission_24.pdf},
}

@InProceedings{2015_8,
author    = {Schoeffler, Michael and Stöter, Fabian-Robert and Edler, Bernd and Herre, Jürgen},
title     = {Towards the Next Generation of Web-based Experiments: A Case Study Assessing Basic Audio Quality Following the ITU-R Recommendation BS. 1534 (MUSHRA)},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {1534},
series    = {WAC '15},
pages     = {1--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Listening tests are widely used to assess the quality of audio systems. The majority of such listening tests is conducted in controlled environments with selected participants and pro-fessional audio equipment. In the last few years, conducting listening tests over the Internet, as so called web-based ex-periments, has become popular. A recent study has shown that web-based experiments lead to comparable results as laboratory experiments. Until now, it was only possible to implement a limited num-ber of listening test types as web-based experiments because web standards were missing some crucial features, e. g. sam-ple manipulation of audio streams. With the upcoming of the Web Audio API, a much wider range of listening test types can be implemented as new audio processing features have been introduced. This paper demonstrates which new possibilities are enabled by the Web Audio API. To this end, the ITU-R Recommendation BS.1534 (MUSHRA) is taken as an example.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_8.pdf:pdf},
issn      = {2663-5844},
keywords  = {1534,itu-r recommendation bs,mushra,web-based ex-},
type      = {Paper},
}

@InProceedings{2015_19,
author    = {Schnell, Norbert and Saiz, Victor and Barkati, Karim and Goldszmidt, Samuel},
title     = {Of Time Engines and Masters - An API for Scheduling and Synchronizing the Generation and Playback of Event Sequences and Media Streams for the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {In this article we present an API and a set of Javascript mod- ules for the synchronized scheduling and aligned playback of predetermined sequences of events such as notes, audio seg- ments, and parameter changes as well as media streams (e.g. audio buffers) based on the Web Audio API logical time. The API has been designed to facilitate the development on both ends, the implementation of modules which generate event sequences or media streams as well as the integration of such modules into complex audio applications that require flexible scheduling, playback and synchronization.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_19.pdf:pdf},
issn      = {2663-5844},
keywords  = {Audio Processing,HTML 5,Scheduling,Synchronization,Web Audio API},
type      = {Paper},
}

@InProceedings{2015_14,
author    = {Lazzarini, Victor and Costello, Edward and Yi, Steven and Ffitch, John},
title     = {Extending Csound to the Web},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper discusses the presence of the sound and music computing system Csound in the modern world-wide web browser platform. It introduces the two versions of the sys- tem currently available, as pure Javascript code, and as por- table Native Client binary module with a Javascript inter- face. Three example applications are presented, showing so- me of the potential uses of the system. The paper concludes with a discussion of the wider Csound application ecosys- tem, and the prospects for its future development.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_14.pdf:pdf},
issn      = {2663-5844},
keywords  = {music programming languages,web applications},
type      = {Paper},
}

@InProceedings{2015_EA_16,
author    = {Carpentier, Thibaut},
title     = {Binaural synthesis with the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {0--7},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {The Web Audio API is a powerful new platform for audio rendering within the browser and it provides a great opportunity for large deployment of audio applications. This paper explores the possibilities and limitations of the API for 3D sound spatialization based on binaural synthesis over headphones. The paper examines different processing structures and presents a new web-based server which allows the user to load individualized Head-Related Transfer Functions from a remote database.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_16.pdf:pdf},
keywords  = {3d audio,binaural rendering,dio api,hrtf,sound spatialization,virtual loudspeakers,web au-},
type      = {Poster},
url       = {http://wac.ircam.fr/program.html},
}

@InProceedings{2015_23,
author    = {Kleimola, Jari},
title     = {DAW Plugins for Web Browsers},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {A large collection of Digital Audio Workstation (DAW) plugins is available on the Internet in open source form. This paper explores their reuse in browser environments, focusing on hosting options that do not require manual installation. Two options based on Emscripten and PNaCl are introduced, implemented, evaluated, and released as open source. We found that ported DAW effect and sound synthesizer plugins complement and integrate with the Web Audio API, and that the existing preset patch collections make the plugins readily usable in online contexts. The latency measures are higher than in native plugin implementations, but expected to reduce with the emerging AudioWorker node.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_23.pdf:pdf},
issn      = {2663-5844},
keywords  = {daw plugin host,emscripten,ladspa,pnacl,web browser},
type      = {Paper},
}

@InProceedings{2015_29,
author    = {Geronazzi, Michele and Kleimola, Jari and Majdac, Piotr},
title     = {Personalization support for binaural headphone reproduction in web browsers},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {111},
number    = {479},
series    = {WAC '15},
pages     = {1009--1010},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This study consider the issue of providing and individual listening experience for binaural sound reproduction in web browsers via headphones. The proposed solution aims at building a web framwork with Web Audio API, giving support to the download of head-related trafer functions (HRTFs) associated with listener's personal profile from a server and the synchronization between the listener's devices. With each playback device and listener, the individual headphone equalization filters will be computed from headphone transfer functions (HpTFs) stored on the server. At server side, we propose to store the HRTFs and HpTFs in spatially oriented format for acoustics (SOFA). At client-side, we propose to convert the data to a new structure (WAV) ensuring a compatible solution with existing Web Audio API implementations. A binaural rendering implementation in JavaScript acting as a proof-of-concept reveals critical issues related to the native implementation in web browsers.},
doi       = {10.1192/bjp.111.479.1009-a},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_29.pdf:pdf},
issn      = {2663-5844},
type      = {Paper},
}

@InProceedings{2015_17,
author    = {Fiala, Jakub and Segal, Nevo and Rawlinson, Hugh A.},
title     = {Meyda: an audio feature extraction library for the Web Audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
pages     = {1--6},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {There are many existing native libraries and frameworks for feature extraction used in multimedia information retrieval. Many are dependent on highly optimised low level to cope with the high performance requirements of audio analysis. In this paper, we present a new feature extractor library, Meyda, for use with the Web Audio API, and detail its benchmarking. Meyda provides the first library for audio feature in the web client, which will enable music information retrieval systems, complex visualisations and a wide variety of technologies and creative projects that previously were relegated to native software. The Meyda project, including source code and documentation is released under an MIT license.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_17.pdf:pdf},
issn      = {2663-5844},
keywords  = {Audio Feature Extraction,Music Information Retrieval,Web Audio},
type      = {Paper},
}

@InProceedings{2015_EA_13,
author    = {Pendharkar, Chinmay and Bäck, Peter and Wyse, Lonce},
title     = {A Dynamic Audio Experience creation platform in Web Audio},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper describes innovative aspects of the Sonoport Stu- dio, a dynamic audio experience creation platform which will be presented in a demonstration at the 1st Web Audio Con- ference in Paris. Two key components of the platform are 1) Sound Model templates that represent classes of dynamic sonic behaviors, and 2) Interaction Model templates that represent classes of interactive behavior that are commonly mapped to interac- tive sound elements. These components, together with a database of sound files and other authoring tools, comprise an interactive audio ex- perience creation platform which is aimed at a typical cre- ative web designer/developer who wants to take advantage of the new capabilities offered by the Web Audio platform, but may not have a deep synthesis or audio processing back- ground.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_13.pdf:pdf},
keywords  = {audio synthesis,interactive audio,w3c web audio api},
type      = {Poster},
}

@InProceedings{2015_EA_20,
author    = {Burleigh, Ian G. and Schaller, Thilo},
title     = {Quint.js: A JavaScript library for teaching music technology to fine arts students},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
number    = {September},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents quint.js, a JavaScript library for mak- ing interactive HTML/SVG/Web Audio “applets”. Two-di- mensional geometric structures (“machines”) that are based in SVG vector graphics with audible feedback synthesized through Web Audio are used to demonstrate various phys- ical, acoustic, and psychoacoustic phenomena and are ap- plied in teaching music technology courses to fine arts stu- dents. The current core quint.js library and extension modules are a starting point for more extensive integration of Web Audio to support the delivery of course content and for the creation of integrated, interactive lecture notes.},
doi       = {10.13140/RG.2.1.3575.9521},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_20.pdf:pdf},
keywords  = {audio,audio arts,audio engineering,ear training,instruction,javascript,svg,web},
type      = {Poster},
}

@InProceedings{2015_12,
author    = {Pendharkar, Chinmay and Bäck, Peter and Wyse, Lonce},
title     = {Adventures in scheduling, buffers and parameters: Porting a dynamic audio engine to Web Audio},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {At Sonoport, we ported our Dynamic Sound Engine from Adobe's Flash technology to Web Audio. The difference in approaches to threading, scheduling and parameters be- tween Flash and Web Audio created a few challenges for us. These differences and some peculiarities of Web Au- dio required workarounds to be able to implement our Dy- namic Sound Engine in Web Audio. In this paper we dis- cuss three of these workarounds dealing with creating Pa- rameters, scheduling operations and playback position of buffers, and explain how these work-arounds, although not optimal solutions, allowed us to support our use cases. Fi- nally we consider how the upcoming AudioWorker change in the Web Audio specification, is expected to impact these workarounds.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_12.pdf:pdf},
keywords  = {audio synthesis,interactive audio,w3c web audio api},
type      = {Paper},
}

@InProceedings{2015_EA_25,
author    = {Mason, Andrew and Paradis, Matthew},
title     = {Adaptive, Personalised ''in browser'' Audio Compression},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {12--15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Audio quality is very important to the BBC's audience, and unwanted loudness variations reduce the quality of the listeners' experience. Dynamic range control applied by the broadcaster can go some way to avoiding problems but, because the broadcaster cannot take into account each listener's individual environment, needs, or preference, it cannot please everyone all the time. The listening conditions are a significant factor to be taken into account when dynamic range control is applied. The Web Audio API offers the possibility of performing dynamic range control under the control of the listener, tailoring it optimally for their individual situation. We have developed a system that demonstrates that this is achievable in a modern web browser. In it, a compressor is controlled automatically by the environmental noise level measured using the microphone present in most mobile device audio players.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_25.pdf:pdf},
keywords  = {broadcasting,object based audio,web audio api},
type      = {Poster},
url       = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.684.2240&rep=rep1&type=pdf},
}

@InProceedings{2015_EA_32,
author    = {Denoux, Sarah and Letz, Stéphane and Orlarey, Yann and Fober, Dominique},
title     = {Composing a Web of Audio Applications},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {The Web offers a great opportunity to share, deploy and use programs without installation difficulties. In this article we explore the idea of freely combining/composing real-time audio applications deployed on the Web using Faust audio DSP language.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_32.pdf:pdf},
keywords  = {composability,dsp programming,faust,web},
type      = {Poster},
}

@InProceedings{2015_EA_18,
author    = {Buffa, Michel and Hallili, Amine and Gonin, Philippe Renevier},
title     = {MT5 : a HTML5 multitrack player for musicians},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {MT5 is a multitrack player based on the Web Audio API [1]. It's open source, runs on multiple devices (all recent desktop browsers except IE, all IOS browsers based on Safari Mobile, Android Chrome, Opera and Firefox mobile). It has been entirely developed in a web browser using the Cloud9 online JavaScript IDE. A demo version can be tried online at http://mt5demo.gexsoft.com while another version that proposes rock classics song by original artists has a restricted access (http://mt5.gexsoft.com).},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_18.pdf:pdf},
keywords  = {e-learning,javascript,web audio,web based ide},
type      = {Poster},
}

@InProceedings{2015_EA_15,
author    = {Ziya, Ehsan},
title     = {Scrolling Through Sound - Scrolling as a method of interaction with audio on the web},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper aims to investigate the creative uses of scrolling as an interaction method for navigating through sound and music. Mainly focused on the use of granular synthesis, the paper explores the interaction model and technical chal- lenges and presents a prototype as proof of concept to demon- strate a case in which scrolling can be used to create an immersive and interactive audio experience on the web. Link to prototype: zya.github.io/scrollsound},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_15.pdf:pdf},
keywords  = {generative,granular synthesis,interactive audio,javascript,music,scrolling,web audio api},
type      = {Poster},
}

@InProceedings{2015_39,
author    = {Roma, Gerard and Serra, Xavier},
title     = {Music performance by discovering community loops},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Technologies for discovering sounds in large databases can help breaking the boundary between exploration and music performance. In this paper, we present a system for explor-ing loops from Freesound. Sound files are grouped by their most common repetition periods, so that they can be played in sync. A graph layout algorithm is used to organize sounds in a two-dimensional plane so that loops with similar timbre are spatially close. The result is a system that can be used as a musical instrument: since sounds will always play in sync, the user can freely explore the variety of sounds uploaded by the Freesound community, while continuously producing a rhythmic music stream.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_39.pdf:pdf},
keywords  = {Audio discovery,music loops,web audio},
type      = {Paper},
}

@InProceedings{2015_26,
author    = {Wyse, Lonce},
title     = {Spatially Distributed Sound Computing and Rendering Using the Web Audio Platform},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Large multi-channel spatial audio systems have historically been play-grounds for universities and well-funded studios, but only a dream for independent composers. Similarly, "parallel computers" were locked in research facilities, where only a few musicians ever gained access to, for example, the compute power to convolve hundreds of separate audio streams with spatially- specific room impulse responses. Mobile devices in the hands of audiences can quickly configure themselves into such systems at very affordable (and distributed) cost and little effort, making powerful and expressive spatially distributed musical platforms accessible to anyone today. We describe some software systems and artistic works that have been developed recently to explore some of the spatial audio capabilities of the mobile device browser platform.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_26.pdf:pdf},
issn      = {2663-5844},
keywords  = {audience participation,distributed computing,interactive audio,spatial audio,web audio api},
type      = {Paper},
}

@InProceedings{2015_EA_30,
author    = {Robaszkiewicz, Sébastien and Schnell, Norbert},
title     = {Soundworks - A Playground for Artists and Developers to Create Collaborative Mobile Web Performances},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {We present Soundworks, a Javascript framework that en- ables artists and developers to create collaborative music performances where a group of participants distributed in space use their smartphones to generate sound and light through touch and motion. The framework adopts a modu- lar architecture to make it easy to implement different per- formance scenarios, using a server / client architecture sup- ported by Node.js and socket.io. We provide a boilerplate that allows anyone to bootstrap a scenario for Soundworks and focus on its audiovisual and interaction design instead of the infrastructure. We developed three scenarios based on Soundworks: Wandering Sound, Drops, and Paths. Each scenario has been tested multiple times with teenagers dur- ing workshops at the Centre Pompidou's Studio 13/16 in Paris. We present the results of these live tests.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_30.pdf:pdf},
keywords  = {HTML5,Web Audio API,collect,mobile music,music},
type      = {Poster},
url       = {http://wac.ircam.fr/pdf/demo/wac15_submission_30.pdf},
}

@InProceedings{2015_27,
author    = {Saiz, Victor and Matuszewski, Benjamin and Goldszmidt, Samuel and Stravinsky, Place Igor},
title     = {Audio oriented UI components for the web platform},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
pages     = {1--5},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper presents a set of web-native tools for visualis- ing and interacting with time-based objects. These visu- alisations are rendered as part of the document using web standard technologies, allowing for an easy integration and interaction with the elements on the same document with- out the help of non-native technologies such as Adobe Flash, Microsoft's Silverlight or Oracle's Java.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_27.pdf:pdf},
keywords  = {ecmascript,graphical user interface,html5,interaction,open web standards,visualisation,web components},
type      = {Paper},
}

@InProceedings{2015_EA_35,
author    = {Goldwaser, Raphaël and Freard, Emmanuel},
title     = {Streaming live content to web audio API},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {7--10},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Web Audio API helps to manage sound through a web browser. In most cases, the input is a sound file, fully loaded from a server. Stored in the cache of the browser, it is then transformed using Web Audio API. But we can also want to work with segments of a file. For instance, when streaming live data, Web have to deal with a dataset of undetermined length.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_35.pdf:pdf},
keywords  = {1 audio processing,4,audio streaming,live streaming,real-time processing,technological choices},
type      = {Poster},
url       = {https://github.com/nums/DashJs-WebAudioAPI},
}

@InProceedings{2015_3,
author    = {Mahadevan, Anand and Freeman, Jason and Magerko, Brian and Martinez, Juan Carlos},
title     = {EarSketch: Teaching Computational Music Remixing in an Online Web Audio Based Learning Environment},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {0--5},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {EarSketch is a novel approach to teaching computer science concepts via algorithmic music composition and remixing in the context of a digital audio workstation paradigm. This project includes a Python/Javascript coding environment, a digital audio workstation view, an audio loop browser, a so- cial sharing site and an integrated curriculum. EarSketch is aimed at satisfying both artistic and pedagogical goals of in- troductory courses in computer music and computer science. This integrated platform has proven particularly effective at engaging culturally and economically diverse students in computing through music creation. EarSketch makes use of the Web Audio API as its primary audio engine for play- back, effects processing and offline rendering of audio data. This paper explores the technical framework of EarSketch in greater detail and discusses the opportunities and chal- lenges associated with using the Web Audio API to realize the project.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_3.pdf:pdf},
keywords  = {2015 for the individual,authors,copying,copyright,cs education,music composition,papers by the papers,remixing,social media sharing,web audio},
type      = {Paper},
}

@InProceedings{2015_EA_2,
author    = {Baratè, Adriano and Haus, Goffredo and Ludovico, Luca A and Baldan, Stefano and Mauro, Davide A},
title     = {Music-Related Media-Contents Synchronization over the Web: the IEEE 1599 Initiative},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
number    = {Lim},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {IEEE 1599 is an international standard originally conceived for music, which aims at providing a comprehensive description of the media contents related to a music piece within a multi-layer and synchronized environment. A number of off-line and stand-alone software prototypes has been realized after its standardization, occurred in 2008. Recently, thanks to some technological advances (e.g. the release of HTML5), the engine of the IEEE 1599 parser has been ported on the Web. Some non-trivial problems have been solved, e.g. the management of multiple simultaneous media streams in a client-server architecture. After providing an overview of the IEEE 1599 standard, this article presents a survey of the recent initiatives regarding audio-driven synchronization over the Web.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_2.pdf:pdf},
keywords  = {H53 [Gro,H55 [Sound and Music Computing]: Systems,Synchronization,Web applications,XML},
type      = {Poster},
url       = {https://wac.ircam.fr/pdf/demo/wac15_submission_2.pdf},
}

@InProceedings{2015_40,
author    = {Mann, Yotam},
title     = {Interactive Music with Tone.js},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper discusses the features, architecture and implementation of Tone.js, a Web Audio framework to facilitate the creation of interactive music specifically suited to the affordances of the browser.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_40.pdf:pdf},
issn      = {2663-5844},
keywords  = {Design,Effects,Human Factors Keywords Signal Processing,J12 [Human-centered computing]: Web-based interac-,Library,Music,Performance,Synthesis,Web Audio API},
type      = {Paper},
}

@InProceedings{2015_EA_31,
author    = {Rossignol, Mathias and Lafay, Gregoire and Lagrange, Mathieu and Misdarris, Nicolas},
title     = {SimScene: a web-based acoustic scenes simulator*},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
pages     = {1--7},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {We introduce in this paper a soundscape simulator called SimScene, designed to be used as an experimental tool to characterize the mental representation of sound environments. The soundscape simulator allows a subject to generate a full sonic environment by sequencing and mixing sound elements , and manipulating their sound level and time positioning. To make the simulation process effective, SimScene has not be designed to manipulate individual parameters of individual sounds, but to specify high-level parameters for whole classes of sounds, organized into a hierarchical semantically structured dataset. To avoid any linguistic bias, a listening oriented interface allows subjects to explore the dataset without any text written help. The entire software is developed in Javascript using the standard Web Audio technology , and is thus fully supported by most modern web browsers. This fact should allow experimenters to adopt a crowdsourcing approach to experimentation in order to assess hypotheses on large populations, and facilitate the development of experimental protocols to investigate the influence of socio-cultural background on soundscape perception .},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_31.pdf:pdf},
keywords  = {H55 [Sound and Music Computing]: Signal analysis,Human Factors Keywords sound perception,Simulation,and processing General Terms Audio,cognitive psychology,soundscape,synthesis,web-based acoustic scenes sim-ulator,web-based sound environment generator,web-based soundscape simulator},
type      = {Poster},
url       = {http://wac.ircam.fr/},
}

@InProceedings{2015_33,
author    = {Taylor, Ben and Allison, Jesse},
title     = {BRAID : A Web Audio Instrument Builder with Embedded Code Blocks},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {Braid (Browser Audio Interface and Database) is a web audio instrument-building environment developed with the NexusUI platform. To identify the requirements of such an environment, the utility of NexusUI as an audio interface engine for browser-based projects is reviewed. The addition of inline web audio within a drag-and-drop interface-building environment is discussed. A consideration of a modified Model-View-Controller architecture to integrate DSP code and interface is followed by an examination of the work-flow of designing browser-based instruments within Braid. Finally, a database for saving and sharing web audio instruments for performance or audience distribution is described.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_33.pdf:pdf},
issn      = {2663-5844},
keywords  = {audio,audio interface,creative code,digital,instrument design,live-coding user interface,mvc,web audio},
type      = {Paper},
}

@InProceedings{2015_7,
author    = {Paradis, Matthew and Gregory-Clarke, Rebecca and Melchior, Frank},
title     = {VenueExplorer , Object-Based Interactive Audio for Live Events},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {VenueExplorer is a new approach to broadcasting live events which gives more control to the audience than traditional viewing methods. Users can navigate around an ultra-high resolution video, zooming into the areas of the event which interest them and accessing extra content. VenueExplorer aims to be platform independent and runs in the browser. In this paper we describe the development of object-based audio rendering to create a more engaging and personalised experience than that of video alone. We use the Web Audio API (WAAPI) to process audio based on the users viewport. We also describe a library that has been developed as part of this project for the handling of location based audio objects.},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_7.pdf:pdf},
issn      = {2663-5844},
keywords  = {broadcasting,object based audio,web audio api},
type      = {Paper},
}

@InProceedings{2015_22,
author    = {Walker, William and Belet, Brian},
title     = {Birds of a Feather ( Les Oiseaux de Même Plumage ): Dynamic Soundscapes using Real-time Manipulation of Locally Relevant Birdsongs},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {This paper and live audio demonstration explores the capabilities of using Web Audio API as a digital audio workstation (DAW) to manipulate sounds from massive server-side databases. Sonic source material comes from a database of birdsongs recorded worldwide by volunteer recordists at xeno-canto.org. Sounds from xeno-canto are chosen to match recent, nearby bird sightings submitted by volunteer birders at eBird. The result is a virtual soundscape derived from the sounds of birds currently present in the user's geographical region. Our client-server architecture delegates database queries and archival storage to the server, leaving the client to concentrate on the aesthetic context of sound modification and manipulation. Engineering issues include separation of client versus server concerns and mashups of crowdsourced databases. Aesthetic issues include which tasks are automated server-side, which are user-controlled client-side, and why. Social issues include single user versus multiple user paradigms, artistic soundscape composition versus commercial applications (e.g., games with evolving sound tracks) using public domain sound sources, music as foreground art versus background audio content, and the larger role of sound and music in current society. Audio results will be demonstrated as each topic is addressed. All the source code for this project is free available under the MIT License at [https://github.com/wfwalker/loco-xeno-canto]. A live demo is at [http://birdwalker.com:9090/quartet.html]},
file      = {:Users/Hjem/Documents/WAC Papers/2015/wac15_submission_22.pdf:pdf},
issn      = {2663-5844},
keywords  = {ds of a feather,dynamic soundscapes using real-time,les oiseaux de même,locally relevant birdsongs,manipulation of,plumage},
type      = {Paper},
}

@InProceedings{2015_EA_37,
author    = {Roma, Gerard and Serra, Xavier},
title     = {Querying Freesound with a microphone},
booktitle = {Proceedings of the International Web Audio Conference},
year      = {2015},
editor    = {Goldszmidt, Samuel and Schnell, Norbert and Saiz, Victor and Matuszewski, Benjamin},
volume    = {i},
series    = {WAC '15},
address   = {Paris},
month     = jan,
publisher = {IRCAM},
abstract  = {On the web, searching for sounds is usually limited to text queries. This requires adding textual descriptions to each audio file, which is indexed effectively as a text document. Recent developments in browser technologies allow developers to access the audio input or microphone of the computer, enabling Query by Example (QbE) applications. We present a demonstration system that allows users to make queries on Freesound.org by recording audio in the browser. A basic prototype is available online.},
file      = {:Users/Hjem/Downloads/drive-download-20190915T212022Z-001/2015/posters/wac15_submission_37.pdf:pdf},
keywords  = {Query by example,audio retrieval,web audio},
type      = {Poster},
url       = {http://mtg.upf.edu/system/files/publications/querying.pdf},
}