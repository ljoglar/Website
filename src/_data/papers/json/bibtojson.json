{"commentsBefore":[],"preamble":null,"entries":[{"type":"inproceedings","id":"2017_EA_47","properties":{"abstract":{"value":"We propose a performance that uses web audio technologies to present a unique solution to the challenge of pairing music with the unpredictable choices and actions of diners in a restaurant. Three small dishes by a well-regarded London chef will be served, and audience members will experience a customized music pairing deployed via a web app running on their own mobile devices.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Houge, Ben and Youssef, Jozef","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/47.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Quiver , Pop , and Dissolve : Three Essays in Gastromorphology}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_70","properties":{"abstract":{"value":"This performance invites the audience to participate in an immersive experience using their mobile devices. The aim is at capturing their actions on a digital painting inspired by Jackson Pollock's action painting technique. The audience is connected to a wireless network and a Web Audio ap- plication that recognizes a number of gestures through the mobile accelerometer sensor, which trigger different sounds. Gestures will be recognized and mapped to a digital can- vas. A set of loudspeakers will complement the audience's actions with ambient sounds. The performance explores au- dio spatialization using both loudspeakers and mobile phone speakers, that combined with the digital painting provides an immersive audiovisual experience. The final digital can- vas will be available online as a memory of the performance.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Anfam, David","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"doi":{"value":"10.1093/gao/9781884446054.article.t000382","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/70.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"0--1","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Hyperconnected Action Painting}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_10","properties":{"abstract":{"value":"These demonstrations will allow visitors to prototype gestural, interactive musical instruments in the browser. Different browser based synthesisers can be controlled by either a Leap Motion sensor or a Myo armband. The visitor will be able to use an interactive machine learning toolkit to quickly and iteratively explore different interaction possibilities. The demonstrations show how interactive, browser-based machine learning tools can be used to rapidly prototype gestural controllers for audio. These demonstrations showcase RapidLib, a browser based machine learning library developed through the RAPID-MIX project.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Parkinson, Adam and Zbyszynski, Michael and Bernardo, Francisco","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/10.pdf:pdf","brace":"curly"},"keywords":{"value":"Article","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"1--2","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Demonstrating Interactive Machine Learning Tools for Rapid Prototyping of Gestural Instruments in the Browser}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"url":{"value":"http://maximilian.strangeloop.co.uk/%0Ahttps://qmro.qmul.ac.uk/xmlui/handle/123456789/26150","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_29","properties":{"abstract":{"value":"Soundtrap is an online music studio and DAW built using the latest Web Audio, Web MIDI and WebRTC standards and supported across nearly all major browsers. With over 1.5 million users and a focus on collaborative music pro- duction, the platform is used in both consumer and educa- tional contexts around the world. Soundtrap aims to create an easy-to-use environment for users who are just getting started with music production, while still providing the ad- vanced features required by more experienced users. The platform allows users to connect and compose music together using MIDI, live instruments and voice, in addition to providing a wide variety of loops and effects. Inside the studio users have access to integrated video chat over We- bRTC, enabling instant feedback with collaborators as they create projects together in real-time. Soundtrap also works on a variety of hardware and plat- forms, scaling the audio experience to work on devices rang- ing from high end workstations to Chromebooks and mobile (Android and iOS). This scaling is made transparent to the user by auto-detecting basic performance characteristics on startup and during studio sessions, and modifying the Web Audio graph as necessary. The studio also uses a few addi- tional techniques to work around device-specific challenges, such as freezing finished tracks within a project to ease the runtime CPU load, doing some processing server-side where possible, and using libvorbis through emscripten to encode large WAV files to ease memory requirements. As Soundtrap wants to match the functionality and per- formance of a native application DAW there are still some challenges encountered around issues like audio latency, streaming, disk usage, and greater access to multiple CPU cores. To this end Soundtrap developers are contribut- ing code towards lower audio latencies in the Chromium browser and are closely following work on the Web Audio spec around things like AudioWorklets. There is also work being done on new projects around things like ”live jamming” with Web Audio over WebRTC, and integrations with other open-source projects like Google Magenta.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Lind, Fredrik and MacPherson, Andrew","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/29.pdf:pdf","brace":"curly"},"keywords":{"value":"Other","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"3--4","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Soundtrap: A collaborative music studio with Web Audio}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"url":{"value":"https://qmro.qmul.ac.uk/xmlui/handle/123456789/26162","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_51","properties":{"abstract":{"value":"trackswitch.js is a versatile web-based audio player that en- ables researchers to conveniently present examples and re- sults from scientific audio processing applications. Based on a multitrack architecture, trackswitch.js allows a listener to seamlessly switch between multiple audio tracks, while syn- chronously indicating the playback position within images associated to the audio tracks. These images may corre- spond to feature representations such as spectrograms or to visualizations of annotations such as structural boundaries or musical note information. The provided switching and playback functionalities are simple yet useful tools for an- alyzing, navigating, understanding, and evaluating results obtained from audio processing algorithms. Furthermore, trackswitch.js is an easily extendible and manageable soft- ware tool, designed for non-expert developers and unexperi- enced users. Offering a small but useful selection of options and buttons, trackswitch.js requires only basic knowledge to implement a versatile range of components for web-based audio demonstrators and user interfaces. Besides introduc- ing the underlying techniques and the main functionalities of trackswitch.js we provide several use cases that indicate the flexibility and usability of our software for different audio- related research areas.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Werner, Nils and Balke, Stefan and St{\\\"{o}}ter, Fabian-robert and M{\\\"{u}}ller, Meinard and Edler, Bernd","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/51.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{trackswitch.js: A Versatile Web-Based Audio Player for Presenting Scientific Results}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_73","properties":{"abstract":{"value":"Music content providers on the Internet like YouTube1, Spotify2 or Apple Music3, as well as a range of software playback systems like the media player “foobar2000”4 have a loudness normalization feature to match a series of diverse audio tracks in overall loudness. This is done to keep perceived volume differences between audio tracks as low as possible. Thus, it is important for music producers, especially mastering engineers, to master audio tracks with a particular amount of dynamic range, so that streaming services will not turn the playback volume of their tracks down. With their already low dynamic range, a listener would now even better be able to recognize their inferior sound compared to other tracks with higher dynamic range. To correctly assess the dynamics of audio material, this paper introduces two web applications that compute and visualize the loudness and dynamic range of audio material, using a subset of the loudness units described in the recommendation R 1285 by the European Broadcasting Union6, and using only native notes by the W3C Web Audio API7.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Zimmer, Sebastian","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/73.pdf:pdf","brace":"curly"},"keywords":{"value":"dynamic range,ebu r 128,loudness,web audio api","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{An approach to assess loudness and dynamics with Web Audio native nodes}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_24","properties":{"abstract":{"value":"Auditory and multimodal presentation of data (“auditory graphs”) can allow for discoveries in a data set that are sometimes impossible with visual-only inspection. At the same time, multimodal graphs can make data, and the STEM fields that rely on them, more accessible to a much broader range of people, including many with disabilities. There have been a variety of software tools developed to turn data into sound, including the widely-used Sonification Sandbox, but there remains a need for simple, powerful, and more accessible tool for the construction and manipulation of multimodal graphs. Web-based audio functionality is now at the point where it can be leveraged to provide just such a tool. Thus, we developed a web application, the Web Soni- fication Sandbox (or simply the Web Sandbox), that allows users to create and manipulate multimodal graphs that convey information through both sonification and visualization. The Web Sandbox is designed to be usable by individuals with no technical or musical expertise, which separates it from existing software. The easy-to-use nature of the Web Sandbox, combined with its multimodal nature, allow it to be a maximally accessible application by a diverse audience of users. Nevertheless, the application is also powerful and flexible enough to support advanced users.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Kondak, Zachary and Liang, Alex and Tomlinson, Brianna and Walker, Bruce N","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/24.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Web Sonification Sandbox - an Easy-to-Use Web Application for Sonifying Data and Equations}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_39","properties":{"abstract":{"value":"This paper introduces lfo — for Low Frequency Opera- tors — a graph-based Javascript (ES2015) API for online and offline processing (i.e. analysis and transformation) of data streams such as audio and motion sensor data. The library is open-source and entirely based on web standards. The project aims at creating an ecosystem consisting of platform-independent stream operator modules such as fil- ters and extractors as well as platform-specific source and sink modules such as audio i/o, motion sensor inputs, and file access. The modular approach of the API allows for us- ing the library in virtually any Javascript environment. A first set of operators as well as basic source and sink modules for web browsers and Node.js are included in the distribu- tion of the library. The paper introduces the underlying concepts, describes the implementation of the API, and re- ports on benchmarks of a set of operators. It concludes with the presentation of a set of example applications.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Matuszewski, Benjamin and Schnell, Norbert","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/39.pdf:pdf","brace":"curly"},"keywords":{"value":"digital signal processing,html5,web audio api","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{LFO – A Graph-based Modular Approach to the Processing of Data Streams}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_55","properties":{"abstract":{"value":"The worlds of the arts, gastronomy, and technology have been colliding and recombining with increasing frequency in recent years, resulting in unusual new forms of expression that engage with all of the senses in a uniquely responsive way. Artists are increasingly seeking to exploit the expressive potential of the chemical senses of smell and taste, while at the same time chefs have been investigating how to refine the narrative, aesthetic, and communicative capabilities of a meal [7]. Web Audio technologies offer a uniquely practicable solution to some of the unexpected challenges that arise when developing multisensory dining experiences, especially when considering the inherently indeterminate nature of a meal. A sophisticated and responsive real-time system is required to respond to diners' unpredictable choices and actions. Siting the source of the sound as close as possible to the food helps reinforce the links between the perception of taste, smell, and sound. Presenting the soundtrack to a meal via the mobile devices that diners are already bringing with them to the restaurant setting provides an innovative, scalable, and cost-effective solution to these challenges. Moreover, by coordinating the music emanating from each diner's device, the restaurant space is transformed into an emergent sound environment, driven by the activities of the diners.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Houge, Ben","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/55.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Web Audio in the Dining Room}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_79","properties":{"abstract":{"value":"Sound effects are employed in the post-production process in order to create tension, atmosphere, and emotion, as well as add focus to desired aspects of a scene. Traditionally sound designers are required to either source these sounds from commercially available libraries or to record audio them- selves. Additionally, sound designers are usually required to manually manipulate these sources in order to accurately sonify the scene. This whole process requires time, planning and effort from the sound designers. While traditional synthesis techniques have been adapted to be incorporated into this process, the synthesisers em- ployed are almost always not designed for this particular purpose. The RTSFX (Real Time Sound Effect Synthesis) web-based platform offers a range of synthesis models tai- lored to recreate a spectrum of sound effects that may be used for this task. An exposed set of parameters allows for the fine tuning and manipulation of a particular sound ob- ject to match the desired characteristics. A basic selection of post processing options is found within the platform to allow for a self-contained sound design process. A browser based platform has been created on which the sounds are generated in real time. A client-side architecture has been employed, allowing for a more flexible workflow for the sound designers. This approach makes it easily accessi- ble to the user, while simultaneously not requiring any per- manent local memory allocation. The browser-based aspect means that the platform is not limited by server availability, while also providing a low latency experience. RTSFX relies on the standardised Web Audio API in or- der to establish a framework for synthesising effects. Differ- ent models can be generated using a mixture of Web-Audio API nodes, customised Javascript processors or Pure Data patches through the use of WebPD or Enzien Audio Heavy. A number of different approaches are used in the model design process. Ranging from accurate representations of physical phenomena, to more perceptually informed quali- tative methods. RTSFX offers a centralised set of elements which may be utilized to build these designs. The platform is an ever growing source of synthesis mod- els with the scope of incorporating more complex techniques which involve the analysis of audio sources in order to gen- erate models.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Vasallo, Thomas and Benito, Adan L","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/79.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Real Time Synthesized Sound Effects Web Service}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_27","properties":{"abstract":{"value":"We propose to present a tube guitar amplifier simulation we've been designing using the Web Audio API with the aim to faithfully reproduce the main parts of the Marshall JCM 800 amplifier schematics. Each stage of the real amp has been recreated (preamp, tone stack, reverb, power amp and speaker simulation). We've also added an extra multiband EQ. This “classic rock” amp simulation we've been building has been used in real gigs and can be favorably compared with some native amp simulation both in terms of latency, sound quality, dynamics and comfort of the guitar play. The amp is open source1 and can be tested online2, even without a real guitar plugged-in. It comes with an audio player, dry guitar samples and a wave generator that can be used as inputs. Figure 1 shows the current GUI, with some optional frequency analyzers and oscilloscopes that we've been using to probe the signal at different stages of the simulation. One purpose was to evaluate the limits of the Web Audio API and see if it was possible to design a web-based guitar amp simulator that could compete with native simulations.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Buffa, Michel and Lebrun, Jerome","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/27.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2--4","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Web Audio Guitar Tube Amplifier vs Native Simulations}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_49","properties":{"abstract":{"value":"In this talk, we present an overview of the experiences we conducted with developers, artists, pedagogues, and many different audiences over the past three years in the frame- work of the CoSiMa research project. The hypothesis of our research was that people would more or less spontaneously take their mobile device out of their pocket to join others around them in making music together. Our methodology basically consisted in trying everything we could and taking on any collaboration that fitted this hypothesis while care- fully observing various design aspects. We have focussed in this work on the exploration of affordances of mobile devices and web standards which we consider to be strong ecologi- cal factors in the development of communication, entertain- ment, and poetry. The talk includes a panorama of the applications and sce- narios (i.e. participative concerts, installations, and work- shops) we have developed over the past three years as well as an overview of the most important findings we have been able to formulate so far. The presentation concludes with a collective improvisation in which we invite the audience to participate.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Schnell, Norbert and Matuszewski, Benjamin","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/49.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"0--1","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Playing ( with ) Mobile Devices and Web Standards ... Together}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_71","properties":{"abstract":{"value":"Sunspots is a web art piece that allows the audience to explore a virtual 3D world. It is an interactive component to a physical audio release on dual-LP vinyl (also called Sunspots), allowing the material to go beyond fixed-media representation. Three environments can be navigated, each with their own audio and visual textures. The visuals make use of Three.js and custom shaders to allow for strange cloth-based physical simulations live in the browser. WebAudio is used for creation and spatialization of the sound in the 3D environment. The audio for each environment is generated by overlapping multiple channels of \"instruments\" that are created by randomly loading different short segments of closely-related analog synthesizer material. These “instruments” are placed in different locations in the virtual world and cause audio-reactive visual behaviors through amplitude detection. Since the project is intended to accompany and compliment the physical audio recording, sample playback is used as opposed to direct WebAudio synthesis. The idea is to create generative versions of the pieces on the album that will vary endlessly and create a unique user experience.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Snyder, Jeff and Wallace, Drew","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/71.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Sunspots}","brace":"curly"},"type":{"value":"Artwork","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_11","properties":{"abstract":{"value":"This work investigates a web-based open environment en-abling collaborative music experiences. We propose an ar-tifact, Open Band, which enables collective sound dialogues in a web \" agora \" , blurring the limits between audience and performers. The systems relies on a multi-user chat system where textual inputs are translated to sounds. We depart from individual music playing experiences in favor of creative participation in networked music making. A previous imple-mentation associated typed letters to pre-composed samples. We present and discuss in this paper a novel instance of our system which operates using Web Audio synthesis.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Stolfi, Ariane and Barthet, Mathieu and Gor{\\'{o}}dscy, F{\\'{a}}bio and Deusany, Antonio and Iazzetta, Fernando","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/11.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Open band: Audience Creative Participation Using Web Audio Synthesis}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"url":{"value":"http://eecs.qmul.ac.uk/$\\sim$keno/11.pdf","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_30","properties":{"abstract":{"value":"The web platform now appears to have all the pieces needed to drive a full live electronic music setup. We can connect to keyboards and controllers using MIDI, synthesise any sound and process live audio. We can also leverage the vast UI toolkit that is HTML and CSS. We can build a DAW (digital audio workstation), but is it solid enough to use realtime on stage? Could we play an entire show with just JavaScript and a few midi controllers? I have been experimenting with this idea for the last couple of years. Using my own software (with a user interface designed specifically for playing live), I've now played a bunch of semi-improvised shows and learnt a whole lot along the way. From user interface design to squeezing as much performance out of Web Audio and JavaScript, I have a lot to share! For reference, here's a selection of videos featuring me playing live electronic music entirely with Web Audio and JavaScript: https:// www.youtube.com/user/mmckegg/videos WEB","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Mckegg, Matt","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/30.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Is Web Audio ready for the Stage / Dancefloor ?}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_52","properties":{"abstract":{"value":"Runaway Reverie is a 3D platformer that also functions as an interactive song. Through the course of the dream-like game, players explore how their movement, location, and interactions with the environment affect musical parameters. This work was built using the Superpowers HTML5 engine using visual assets by Sparklin Labs, and extending the game engine's audio capabilities with Conductor and MultiSoundPlayer classes, which derive inspiration from layer and loop-driven interactive audio engines driven such as FMOD and Wwise. The implementation of these new functionalities demonstrates that such high-level game audio concepts can be applied to Web Audio as well. Finally, the artist hopes that the game will serve as a demonstration that interactive multimedia experiences, especially those that incorporate music and audio as an essential element, can make use of web technologies for ease of access.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Su, David","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/52.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Runaway Reverie}","brace":"curly"},"type":{"value":"Artwork","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_74","properties":{"abstract":{"value":"By investigating the conceptual field of sound, tone, pitch, and timbre in its relation to visual phenomena and geometrical concepts, the project Sound Colour Space – A Virtual Museum contributes to an interdisciplinary field of research and explores its adequate modes of representation and communication. Many scientists and philosophers from antiquity to modern times have studied the relationships between sound, light and geometry. Many of their visualisations of acoustical, optical and perceptual topics speak to the eye and can be studied comparatively. These pictures are interesting because of their diagrammatic structure, in the way they combine text, images and spatial structures on a flat surface and in the way they address topological, philosophical and psychological questions. They often have an aesthetic value of their own. In addition to the development of an exemplary online publication, interactive audiovisual examples were created, which also were used for artistic projects.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Muzzulini, Daniel and Vogtenhuber, Raimund","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/74.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"4--7","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Sound Colour Space – A Virtual Museum*}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_32","properties":{"abstract":{"value":"As a follow up to my talk \"Is Web Audio ready for the stage / dancefloor\" I also submit a demo of the software Loop Drop (http:// loopjs.com) that I will be mostly talking about. I'll also be available to discuss with attendees in more depth about the various associated challenges and the endless possibilities opened up by these new web standards!","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Mckegg, Matt","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/32.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Loop Drop : Live Electronic Music Software powered by Web Audio ( demo )}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_58","properties":{"abstract":{"value":"This paper describes the functions, concept and technical points of WebbyJam ( http://www.webbyjam.com ).","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Takakura, Hiroyuki","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/58.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{WebbyJam, a Web Tune Editor to Find Enjoyment Helpful to Find Enjoyment}","brace":"curly"},"type":{"value":"Artwork","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_80","properties":{"abstract":{"value":"Distributed performance systems that utilize a centralized server for connectivity have the potential to also provide extended computational and storage resources that would not be beneficial or even possible if distributed onto mobile clients. The usage of large datasets, shared or collaborative resources, and processor intensive techniques can be per-formed on the server while allowing time sensitive and less complex user specific computation to occur on client devices. Many of these types of problems can be solved using tools developed for cloud computing. This approach is demon-strated in the work Diamonds in Dystopia, a collaborative poetry performance that incorporates audience interaction on mobile devices, generation of poetic material on server side resources, real-time synthesis distributed through mo-bile and venue speakers, a live poetry reading performance and the live synthesis of poetry from the collective ensem-ble.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Allison, Jesse and Ostrenko, Frederick and Cellucci, Vincent","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/80.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"4--7","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Active Server Roles for Extended Distributed Performance Complexity in Diamonds in Dystopia}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_83","properties":{"abstract":{"value":"In this project we developed a network of cloudspeakers. These are mobile speakers connected to a raspberry pi3 equipped with a low-latency audio card. They are connected to a wifi network and run a SuperCollider-Server (scsynth). Our cloudspeaker can be addressed with the SuperCollider (sclang) in the network. For this purpose we had to create a stable and scaleable network, and we had to find solutions for problems like latency, jitter, or software management. This network can be used for artistic projects and can be combined with a webserver and the use of mobile devices.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Visser, Jeroen and Vogtenhuber, Raimund","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/83.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"4--5","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Cloudspeakers – a mobile performance network}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"url":{"value":"http://eecs.qmul.ac.uk/$\\sim$keno/83.pdf","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_28","properties":{"abstract":{"value":"In listening tests, detailed sound control is sometimes mandatory down to each individual digital sample value and guarantee is needed that they are not unintentionally altered. At other times, a lesser degree of control is ac- ceptable, if on the other hand test execution becomes less restricted. Detailed control of sound is often possible only under “laboratory” conditions where hardware and software are under complete control and sound pressure levels can be accurately calibrated. On the other hand, if test per- sons can do listening tests at home, via an internet browser for example, collecting large amounts of data becomes faster and cheaper (no laboratory facilities required, and more per- sons can do tests in parallel). Online listening tests made possible by the Web Audio API offers great flexibility in test execution, but compromises in precise stimulus control must be accepted. This paper analyzes such compromises by discussing technological limitations of Web Audio API followed by validation measurements of sound playback in popular internet browsers. The measurements show that at the detailed level there are significant di↵erences in ac- tual performance of different browsers and behavior is not always as expected. Finally, a solution is presented where audio presentation is delegated to an external audio presen- ter for situations where the limitations of Web Audio API are not acceptable.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Pedersen, Benjamin","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/28.pdf:pdf","brace":"curly"},"keywords":{"value":"Browser,online audio testing","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Hi-precision audio in listening tests - also in the browser?}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_61","properties":{"abstract":{"value":"This paper introduces a platform for the representation and discovery of live music recordings and associated artefacts based on a dedicated data model. We demonstrate our tech- nology by implementing a Web-based discovery tool for the Grateful Dead collection of the Internet Archive, a large col- lection of concert recordings annotated with editorial meta- data. We represent this information using a Linked Data model complemented with data aggregated from several additional Web resources discussing and describing these events. These data include descriptions and images of phys- ical artefacts such as tickets, posters and fan photos, as well as other information, e.g. about location and weather. The system uses signal processing techniques for the analysis and alignment of the digital recordings. During the discovery, users can juxtapose and compare dierent recordings of a given concert, or different performances of a given song by interactively blending between them.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Wilmering, Thomas and Thalmann, Florian and Sandler, Mark B","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/61.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Towards a Framework for the Discovery of Collections of Live Music Recordings and Artefacts on the Semantic Web}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_12","properties":{"abstract":{"value":"Audio production involves the use of tools such as rever- berators, compressors, and equalizers to transform raw audio into a state ready for public consumption. These tools are in wide use by both musicians and expert audio engineers for this purpose. The typical interfaces for these tools use low-level signal parameters as controls for the audio effect. These signal parameters often have unintuitive names such as “feedback” or “low-high” that have little meaning to many people. This makes them di?cult to use and learn for many people. Such low-level interfaces are also common throughout audio production interfaces using the Web Audio API. Recent work in bridging the semantic gap between verbal descriptions of audio effects (e.g. “underwater”, “warm”, “bright”) and low-level signal parameters has resulted in provably better interfaces for a population of laypeople. In that work, a vocabulary of hundreds of descriptive terms was crowdsourced, along with their mappings to audio effects settings for rever- beration and equalization. In this paper, we present a Web Audio node that lets web developers leverage this vocabulary to easily create web-based audio effects tools that use natural language interfaces. Our Web Audio node and additional documentation can be accessed at https://interactiveaudiolab.github.io/audealize_api.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Donovan, Michael and Seetharaman, Prem and Pardo, Bryan","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/12.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{A Web Audio Node for the Fast Creation of Natural Language Interfaces for Audio Production}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_54","properties":{"abstract":{"value":"Piper is a protocol for audio analysis and feature extraction. We propose a data schema and API that can be used to support both remote audio feature extraction services and feature extractors loaded directly into a host application. We provide a means of using existing audio feature extractor implementations with this protocol. In this talk we demonstrate several use-cases for Piper, including an“audio notebook”mobile application using Piper modules to analyse recordings; a web service for remote feature extraction; and the refactoring of an existing desktop application, Sonic Visualiser, to communicate with a Piper service using a simple IPC mechanism.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Thompson, Lucas and Cannam, Chris and Sandler, Mark","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/54.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2--3","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Piper : Audio Feature Extraction in Browser and Mobile Applications}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_31","properties":{"abstract":{"value":"A completely live electronic music performance with visuals and lighting entirely powered by JavaScript. Following on from my submitted talk \"Is Web Audio ready for the stage/dancefloor\", I along with other members of Live JS (http:// livejs.network) would like to demonstrate that it INDEED is ready! At JSConf.asia, we were given the opportunity to take over the entire venue (including their massive lighting rig) and broadcast our pirate JavaScript signal to everyone for the after party! We'll be doing something similar at JSConf.eu in May (if all goes to plan). Here is a video of our JSConf.asia talk (30mins) and full improvised performance: https://youtu.be/s3fsRnFfyuo?t=2131 Matt, Martin and Tim (possibly more of us, depending on who can come) will be dropping Web Audio powered samples, synthesisers, and looping using multiple midi controllers. We'll also be using JavaScript to drive a massive LED wall, realtime visuals and (if possible) moving head lighting via DMX.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Mckegg, Matt and Schuhfuss, Martin and Pietrusky, Tim","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/31.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2131","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Live JS (performance)}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_75","properties":{"abstract":{"value":"Frabjous day is a live-coding performance using a new, browser-based live-coding environment, gibberwocky, co-developed by the performer with Dr. Graham Wakefi e ld. gibberwocky fea tures deepintegration with Ableton Live, possessing a variety of affordances for both musical sequencing and rapidly creating / assigning audio-rate modulation graphs. Like Gibber, another browser-based envi ronment developed by the performer, gibberwocky places emphasis on dynamic annotations to source code that reveal the state of underlying algorithms. A new addition found only in gibberwocky isthe use of animated sparklines to visually depict synthesis modulations over time. gibberwocky also makes heavy use of a new JavaScript synthesis library, genish.js, to generate musical patterns via digital signal processing techniques.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Roberts, Charlie","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/75.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Frabjous day}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_82","properties":{"abstract":{"value":"Diamonds in Dystopia is a body of work and web framework for creatively datamining large sources of text for mobile in-teraction. So far we have used it for live-streaming poetry performances at various locations such as SXSW Interactive and TEDx in addition to fine arts installations. As a perfor-mance it is a web driven app for incorporating improvisation into experiential storytelling. The audience acts as collab-orator by sending word selections by tapping language on their mobiles to trigger reactions to send a distilled, impro-visational stanza culled from a massive corpus of text to the poet on stage. The individual taps coming from the audi-ence also trigger synthesized audio effects at varying pitches to create a musical experience as well as contributing to a vi-sual projection of the poem and audience interactivity. Cre-ated by Vincent A. Cellucci (poet), Jesse Allison (Professor of Experimental Music), and Derick Ostrenko (Professor of Digital Art), the applications use natural language process-ing on text to generate an innovative media stage project. The app creators are interested in creative data mining and incorporating interactive media into performances that chal-lenge people's perceptions and expectations for the mediums of music, digital art and design, and poetry.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Allison, Jesse and Ostrenko, Frederick and Cellucci, Vincent","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/82.pdf:pdf","brace":"curly"},"keywords":{"value":"Other","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2--3","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Diamonds in Dystopia}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"url":{"value":"https://qmro.qmul.ac.uk/xmlui/handle/123456789/26168","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_14","properties":{"abstract":{"value":"WebX0X Version 2 is a performance-oriented drum synthesizer and sequencer built using the Web Audio API.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Wallace, Tony","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/14.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"0--1","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{WebX0X Version 2}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_34","properties":{"abstract":{"value":"88 Fingers is a performance in which up to 88 players in the audience perform on an automatized piano (i.e. a YAMAHA Disklavier) via their mobile devices. The piano is presented in the performance space as if it would be the instrument of a solo performer (e.g. on stage or in the center of the space). Apart from the web-based system that allows the participants to select a single key of the piano and to play it during the concert, the concept of the performance does not impose any further constraints. The performance is structured into two parts of 10 min- utes separated by a discussion among the members of the audience of approximately 10 minutes. The experience establishes a metaphor of a free and re- sponsible society.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Schnell, Norbert and Matuszewski, Benjamin","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/34.pdf:pdf","brace":"curly"},"keywords":{"value":"Other","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"4--5","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{88 Fingers}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"url":{"value":"https://qmro.qmul.ac.uk/xmlui/handle/123456789/26172","brace":"curly"},"volume":{"value":"5","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_59","properties":{"abstract":{"value":"In this paper, we report on developments of the Citygram, a comprehensive sensor network platform for capturing, streaming, analyzing, mapping, visualizing, and providing easy access to spatiotemporal soundscape data. Launched in 2011, Citygram's recent strategic decision has resulted in system redesign to enable migration from a codebase built on multiple computer languages to a cross-platform single JavaScript codebase. Citygram now runs on V8 engines including standard web-browsers and in the node.js environment. The Citygram sensor network significantly alleviates problems concerning soundmapping complexities including operating system limitations, hardware dependency, software update and dissemination issues, data access mechanism, data visualization, and cost. This strategy has made practicable a key design philosophy for soundmapping: rapid sensor network growth for capturing spatiotemporally granular soundscapes. We summarize research and development for the following Citygram modules (1) cost-effective sensor module allowing high-value data transmission through edge compute paradigms, (2) machine learning module focusing on environmental sound classification, and (3) visualization and data access prototypes.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Park, TH and Yoo, M","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/59.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Practicable Soundmapping: JavaScript enabled Edge Compute}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"url":{"value":"http://qmro.qmul.ac.uk/xmlui/handle/123456789/26125","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_20","properties":{"abstract":{"value":"Freesound Explorer is a visual interface for exploring Freesound content in a two-dimensional space and creating music by linking content in that space. Freesound Explorer is implemented as a web application which takes advantage of modern web technologies including the Web Audio API and the Web MIDI API. This extended abstract describes Freesound Explorer's features and provides some technical details about its implementation.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Font, Frederic and Bandiera, Giuseppe","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/20.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Freesound Explorer: Make Music While Discovering Freesound!}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"url":{"value":"https://repositori.upf.edu/bitstream/handle/10230/32538/font_wac_freesound.pdf?sequence=1&isAllowed=y","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_84","properties":{"abstract":{"value":"This paper describes the ongoing development of a system for the creation of a distributed musical space: the Mu- sicBox. The MusicBox has been realized as an open access point for mobile devices. It provides a musical web applica- tion enabling the musician to distribute audio events onto the connected mobile devices and control synchronous play- back of these events. In order to locate the mobile devices, a microphone array has been developed, allowing to automatically identify sound direction of the connected mobile devices. This makes it possible to control the position of audio events in the musical space. The system has been implemented on a Raspberry Pi, making it very cheap and robust. No network access is needed to run the MusicBox, turning it into a versatile tool to setup interactive distributed music installations.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Milde, Jan-Torsten","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/84.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Synchronized mobile devices using web audio technology on a Raspberry Pi}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_62","properties":{"abstract":{"value":"We introduce a prototype of an educational web application for comparative performance analysis based on source sepa- ration and object-based audio techniques. The underlying system decomposes recordings of classical music performances into note events using score-informed source separation and represents the decomposed material using semantic web tech- nologies. In a visual and interactive way, users can explore individual performances by highlighting specific musical as- pects directly within the audio and by altering the temporal characteristics to obtain versions in which the micro-timing is exaggerated or suppressed. Multiple performances of the same work can be compared by juxtaposing and blending between the corresponding recordings. Finally, by adjusting the timing of events, users can generate intermediates of multiple performances to investigate their commonalities and differences.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Thalmann, Florian and Ewert, Sebastian and Wiggins, Geraint and Sandler, Mark B","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/62.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Exploring Musical Expression on the Web: Deforming, Exaggerating, and Blending Decomposed Recordings}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_13","properties":{"abstract":{"value":"Open Band is a collective performance, that deals with a contradiction of the social media, that is the apartness of the individual on their devices social media, to propose a collec- tive sound intervention, were a conductor interacts with the audience through an anonymous chat interface that converts text into sound messages. In this version, we are working only with web audio synthesis, based on an idea of audio typography.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Stolfi, Ariane and Barthet, Mathieu and Gor{\\'{o}}dscy, F{\\'{a}}bio","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/13.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Open Band : Audiotype}","brace":"curly"},"type":{"value":"Performance","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_44","properties":{"abstract":{"value":"The JavaScript Web Audio API has a powerful but low-level and complicated structure. Therefore, many JavaScript-based wrapper libraries exist, which are intended to simplify its usage. This paper presents a completely new approach, which translates the API into HTML Custom Elements and allows definition, usage and control of complex audio scarios using only normal HTML elements.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Volke, Stephanus and Bechtold, Bastian and Bitzer, Joerg","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/44.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"7--8","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{HTML Web Audio Elements : Easy Interaction with Web Audio API Through HTML}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_67","properties":{"abstract":{"value":"This poster introduces the implementation of the ARCADE 3D-audio codec for web browsers. ARCADE can embed a full 3D audio scene in a simple stereo- compatible audio stream that can be further compressed with standard lossy compression schemes, aired to analog or digital radio receivers or even stored on analog supports. An ARCADE- encoded stream can be decoded to any 2D or 3D-audio rendering format, for instance using Vector-Based Amplitude Panning (VBAP), Higher Order Ambisonics (HOA), or personalized binaural with headtracking. ARCADE adapts seamlessly to the audio industry needs, from storage to production, distribution/delivery, and rendering. It finds uses in Virtual or Augmented Reality (VR/AR), movies, gaming, music, telepresence & teleconferencing. We present a JavaScript (JS) and Web Audio API implementation of the ARCADE decoder, which was originally written in C++11, along with technical details of the porting operations. Live demos of 3D-audio content transmission, decoding and dynamic binaural rendering will be given during the poster session.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Becker, Fran{\\c{c}}ois and Bernard, Benjamin and Carron, Cl{\\'{e}}ment","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/67.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{ARCADE 3D-audio codec: an implementation for the web}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_17","properties":{"abstract":{"value":"In this paper we present BAT (BMAT Annotation Tool), an open-source, web-based tool for the manual annotation of events in audio recordings developed at BMAT (Barcelona Music and Audio Technologies1). The main feature of the tool is that it provides an easy way to annotate the salience of simultaneous sound sources. Additionally, it allows to define multiple ontologies to adapt to multiple tasks and of- fers the possibility to cross-annotate audio data. Moreover, it is easy to install and deploy on servers. We carry out an evaluation where 3 annotators use BAT to annotate a small dataset composed of broadcast media recordings. The results of the experiments show that BAT offers fast an- notation mechanisms and a method to assign salience that produces high agreement among annotators.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Mel{\\'{e}}ndez-Catal{\\'{a}}n, Blai and Molina, Emilio and G{\\'{o}}mez, Emilia","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/17.pdf:pdf","brace":"curly"},"keywords":{"value":"annotation tool,audio events,open-source,web-based","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"3--6","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{BAT: An open-source, web-based audio events annotation tool}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_37","properties":{"abstract":{"value":"Music production is a complex process requiring skill and time to undertake. The industry has undergone a digital revolution, but unlike other industries the process has not changed. However, intelligent systems, using the semantic web and signal processing, can reduce this complexity by making certain decisions for the user with minimal interac- tion, saving both time and investment on the engineers' part. This paper will outline an intelligent Digital Audio Work- station (DAW) designed for use in the browser. It outlines the architecture of the DAW with its audio engine (built on the Web Audio API), using AngularJS for the user interface and a relational database.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Jillings, Nicholas and Stables, Ryan","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/37.pdf:pdf","brace":"curly"},"keywords":{"value":"Article","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{An Intelligent audio workstation in the browser}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"url":{"value":"https://qmro.qmul.ac.uk/xmlui/handle/123456789/26146","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_60","properties":{"abstract":{"value":"After a first version based on asm.js [4], we show in this paper how the Faust audio DSP language can be used to generate ecient Web Audio nodes based on WebAssem-bly. Two new compiler backends have been developed. The libfaust library version of the compiler has been compiled for the Web, thus allowing to have an ecient compilation chain from Faust DSP sources and libraries to audio nodes directly available in the browser.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Letz, St{\\'{e}}phane and Orlarey, Yann and Fober, Dominique","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/60.pdf:pdf","brace":"curly"},"keywords":{"value":"audio,domain specific,dsp,faust,language,or musical languages,real-time,various javascript dsp libraries,web audio api,webassembly","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Compiling Faust audio DSP code to WebAssembly}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"url":{"value":"http://eecs.qmul.ac.uk/$\\sim$keno/60.pdf","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_22","properties":{"abstract":{"value":"There is a reason why the sentence \"bring your own headphones\" is part of every invitation to an audio related hackathon. And of course the whole point of working with audio engines like the Web Audio API is to create impressive sonic experiences. But while building such an experience it can quickly become cumbersome to test the same sound over and over again. A hackathon project might not need any tests at all, but more mature projects will benefit from tests which can be run automatically. This is even more important for projects which deal with ever evolving APIs like the Web Audio API. Every browser update may introduce a breaking change. If you don't have automated tests to check if everything still works as expected, you might need to keep your headphones at hand. I would like to introduce a new category of tests which I call expectation tests. The idea behind expectation tests is to separate code which deals with browser anomalies from the business logic. This opens up the possibility to write code as if you dealt with one single (perfect) browser. Whenever there is a shortcoming in a supported browser which needs to be patched with a polyfill, this should be accompanied by an expectation test which checks if the browser still behaves wrongly. Later on this test will break when the polyfill can be removed again. This makes sure that only necessary patches are part of the production code. In addition to that, the polyfills should be completely separate from any business logic. Instead the polyfills should make sure to provide a uniform API in each supported browser, which then can be used by the business logic. Another benefit from using expectation tests is that it's not necessary anymore to test your business logic with the \"real\" Web Audio API. I would like to present a framework which mocks the Web Audio API and allows to advance the currentTime of an AudioContext in a controlled way to make sure scheduling and AudioParam automations work correctly.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Guttandin, Christoph","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/22.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Noiseless Web Audio Tests}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_9","properties":{"abstract":{"value":"Scientists of many audio-related fields need to verify their theories by conducting controlled experiments with human test subjects. The process of developing and conducting such experiments often poses non-trivial challenges to scientists and test subjects. Web technologies promise simple delivery of experiments as interactive websites, possible even on subjects' own computers. Similar benefits are possible for teaching science. While many tasks in hearing experiments and teaching are well-supported with current web-based tools, suuport for scientific data structures, signal processing operations and statistical data analysis methods is still incomplete in comparison with entrenched non-web tools. These shortcomings could easily be overcome with a few libraries, and would provide a great boon to scientists and educators.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Bechtold, Bastian and Volke, Stephanus and Bitzer, Joerg","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/9.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Web Technologies for Scientific Hearing Experiments and Teaching - An Overview}","brace":"curly"},"type":{"value":"Poster","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_43","properties":{"abstract":{"value":"In the context of digital sound archives, an innovative web framework for automatic analysis and manual annotation of audio files has been developed. This web framework, is called Timeside and is available under an open-source li- cense. The TimeSide framework associates an audio processing engine, an audio database, a web API and a client-side mul- timedia player. The audio processing engine is written in Python language and has been designed for speech and audio signal analysis and Music Information Retrieval (MIR) tasks. It includes a set of audio analysis plugins and additionally wraps several state-of-the-art audio features extraction libraries to provide automatic annotation, segmentation and Music Information Retrieval analysis. It also provides decoding and encoding methods for most common multimedia formats. The audio database application is handled through Django (Python) and is interfaced with the audio processing engine. The web API component provides these functionalities over the web to enable web client to run analysis on the sounds in the audio database. Last but not least, the multi- media player provides an web player associated with several sound and analysis visualizations together with an annota- tions editor through a multi-tracks display. The TimeSide platform is available as an open-source project at the following addresses: TimeSide: https://github.com/Parisson/TimeSide","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Fillon, Thomas and Pellerin, Guillaume","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/43.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{A collaborative web platform for sound archives management and analysis}","brace":"curly"},"type":{"value":"Demo","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_63","properties":{"abstract":{"value":"This paper presents the N{\\\"{u}} framework. The objective of the framework is to provide composers with a tool to con- trol web-based audio processes on spectators smartphones during live performances. Connecting their devices to a web- page broadcasted by the performer's laptop, spectators be- come part of the composition: from simple sound sources to active musicians. From a Max based interface, the performer can then control the behaviours of conceptual units, referred to as N{\\\"{u}} modules, designed for live composition (distributed room reverb, granular synthesis, etc.). Each module is com- posed of a pair of JavaScript classes – one for the client, another for the server – relying on the Web Audio API for audio processing, and OSC messages for parameters con- trol. N{\\\"{u}} is an open source project based on the Soundworks framework.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Poirier-Quinot, David and Matuszewski, Benjamin and Schnell, Norbert and Warusfel, Olivier","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/63.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"0--5","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{N{\\\"{u}} Soundworks : Using spectators smartphones as a distributed network of speakers and sensors during live performances.}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_25","properties":{"abstract":{"value":"Music loops are audio recordings used as basic building blocks in many types of music. The use of pre-recorded loops facilitates engagement into music creation to users regard- less of their background in music theory. Using online loop databases also affords simple collaboration and exchange. Hence, music loops are particularly attractive for web audio applications. However, traditional musical audio recording typically relies on complex DAW software. Recording loops usually requires consideration of musical meter and tempo, and withstanding metronome sounds. In this paper, we propose loop-aware audio recording as a use case for web audio technologies. Our approach sup- ports hands-free, low-stress recording of music loops in web- enabled devices. The system is able to detect repetitions in an incoming audio stream. Based on this information, it segments and ranks the repeated fragments, presenting the list to the user. We provide an example implementation, and evaluate the use of the different MIR libraries available in the web audio platform for the proposed task.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Roma, Gerard and Xamb{\\'{o}}, Anna and Freeman, Jason","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/25.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Loop-aware Audio Recording for the Web}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_45","properties":{"abstract":{"value":"Implementing an understandable, accessible and effective user interface is a major challenge for many products in the microcontroller and embedded computing community. Bela, an embedded system for ultra-low latency audio and sensor processing, features a browser-based integrated devel- opment environment (IDE) using web technologies (Node.js, HTML5 and CSS). This methodology has allowed us to cre- ate an IDE that is simplified and intuitive for beginners while still being useful to those more advanced, thus supporting users as they evolve in expertise.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Donovan, Liam and Bin, S M Astrid and Armitage, Jack and Mcpherson, Andrew P","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/45.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"number":{"value":"August","brace":"curly"},"pages":{"value":"0--1","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Building an IDE for an Embedded System Using Web Technologies}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_69","properties":{"abstract":{"value":"This paper describes how parametric equations can be sonified using the Web Audio API and visualized us- ing a vectorscope built using the HTML5 canvas el- ement. A working demonstration can be found at academo.org/demos/vectorscope, with a selection of user- adjustable parametric equations, including Lissajous figures and hypotrochoids.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Ball, Edward","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/69.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"3--4","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Sonification and Visualization of Parametric Equations}","brace":"curly"},"type":{"value":"Artwork","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_40","properties":{"abstract":{"value":"This paper presents the WASABI project, started in 2017, which aims at (1) the construction of a 2 million song knowl-edge base that combines metadata collected from music databases on the Web, metadata resulting from the anal-ysis of song lyrics, and metadata resulting from the audio analysis, and (2) the development of semantic applications with high added value to exploit this semantic database. A preliminary version of the WASABI database is already on-line 1 and will be enriched all along the project. The main originality of this project is the collaboration between the al-gorithms that will extract semantic metadata from the web and from song lyrics with the algorithms that will work on the audio. The following WebAudio enhanced applications will be associated with each song in the database: an online mixing table, guitar amp simulations with a virtual pedal-board, audio analysis visualization tools, annotation tools, a similarity search tool that works by uploading audio extracts or playing some melody using a MIDI device are planned as companions for the WASABI database.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Meseguer-brocal, Gabriel and Peeters, Geoffroy and Pellerin, Guillaume and Buffa, Michel and Cabrio, Elena and Zucker, Catherine Faron and Giboin, Alain and Mirbel, Isabelle and Hennequin, Romain and Moussallam, Manuel and Piccoli, Francesco and Fillon, Thomas","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/40.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{WASABI: a Two Million Song Database Project with Audio and Cultural Metadata plus WebAudio enhanced Client Applications}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"url":{"value":"http://eecs.qmul.ac.uk/$\\sim$keno/40.pdf","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_38","properties":{"abstract":{"value":"The Web Audio API introduced native audio processing into web browsers. Audio plugin standards have been created for developers to create audio-rich processors and deploy them into media rich websites. It is critical these standards support flexible designs with clear host-plugin interaction to ease integration and avoid non-standard plugins. Intelligent features should be embedded into standards to help develop next-generation interfaces and designs. This paper presents a discussion on audio plugins in the web audio API, how they should behave and leverage web technologies with an overview of current standards.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Jillings, Nicholas and Wang, Yonghao and Stables, Ryan and Reiss, Joshua D","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/38.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Intelligent audio plugin framework for the Web Audio API}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"url":{"value":"http://www.eecs.qmul.ac.uk/$\\sim$josh/documents/2017/Jillings - Web Audio Conference.pdf","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_72","properties":{"abstract":{"value":"Due to current browser limitations, most synthesis in the browser is currently performed using the block-rate nodes included in the WebAudio API. However, block-rate pro- cessing of audio graphs precludes many types of synthesis in addition to limiting both the accuracy and flexibility of scheduling. We describe alternative strategies for perform- ing efficient, per-sample processing of audio graphs in the browser using the ScriptProcessor node, affording synthesis techniques that are not commonly found in existing Java- Script audio libraries. We introduce a new library, Genish.js, that provides unit generators for common low-level synthesis tasks and acts as a compiler for signal processing functions; this library is a loose port of the Gen framework for Max/MSP. We used Genish.js to update a higher-level library for audio programming, Gibberish.js, realizing improvements to both efficiency and audio quality. Preliminary benchmarks comparing the performance of Genish.js audio graphs to equivalent graphs made with the WebAudio API show promising results.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Roberts, Charles","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/72.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Strategies for Per-Sample Processing of Audio Graphs in the Browser}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"volume":{"value":"7","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_50","properties":{"abstract":{"value":"Apophenia is an interactive music piece that sets out to explore ways to achieve a balance between artistic narration and interactivity in a generative music system. The piece is an exploration in presenting interactive musical systems with an element of narration. The piece is delivered as an interactive musical system that heavily utilises the Web Audio API for real-time sound synthesis, sampling and audio processing. Users are initially presented with a set of points where each points represents a note. The user can use the mouse to hover over multiple notes to generate chords and trigger melodies by clicking. The piece progresses as the user finds special connections between the notes. These special connections will reveal a visual pattern and eventually the user will discover a new dimension in the piece. Eventually, the piece would go back to the beginning where the user can start from scratch. The visual aspect of the work starts with a 2D interactive system made using pt.js [1] library. The second phase of the experience is in 3D which utilises WebGL through Three.js [2].","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Ziya, Ehsan","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/50.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"2017","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Apophenia}","brace":"curly"},"type":{"value":"Artwork","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_EA_65","properties":{"abstract":{"value":"In preparation to expand the experimental interfaces in NexusUI widgets, the authors have been evaluating physics engines and exploring physics-based user interfaces on the web. Tying physics simulation events, influenced by user interactions, to web audio encourages exploration of novel methods of interactivity between users and web-based in- struments. Object collisions, deformation of a mesh of ob- jects with elastic connections, and liquid simulation via par- ticle generation were identified as systems with dynamics that may provide interesting links to audio synthesis. Two popular physics engines explored are LiquidFun and Mat- ter.js, with new prototype widgets taking advantage of Liq- uidFun's Elastic Particles and Matter.js' Cloth and New- ton's Cradle composites. One of our goals is to discover methods of audio synthesis that complement the behaviors of each physical simulation.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Mitchusson, Chase and Marasco, Anthony T and Allison, Jesse","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/65.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"1--2","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Usage of Physics Engines for UI Design in NexusUI}","brace":"curly"},"type":{"value":"Talk","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_26","properties":{"abstract":{"value":"This paper presents a tube guitar amplifier simulation made with the WebAudio API, that reproduces the main parts of the Marshall JCM 800 amplifier schematics. Each stage of the real amp has been recreated (preamp, tone stack, reverb, power amp and speaker simulation, and we added an extra multiband EQ). The “classic rock” amp simulation we built has been used in real gigs and can be compared with some native amp simulation both in terms of latency, sound quality, dynamics and comfort of the guitar play. Unfortunately, as of today, low latency can be achieved only with certain configurations, due to audio driver limitations of current browsers on certain operating systems. The paper discusses the latency problems encountered with WebAudio, common traps, current limitations, and proposes some solutions. The final web based simulation has been compared with native re- creations of the same amp model (including commercial products such as GuitarRig, the JCM800 amp included in GarageBand or the open source Guitarix amp sim that runs on Linux), and with a real amp: the Yamaha THR10 that comes with a model of a Marshall amp. We conducted both quantitative evaluations (measure of the “guitar-to-speaker” latency, group delay, frequency response analysis) and qualitative evaluations with real guitar players who compared, guitar in hands, the different simulations in terms of sound quality and dynamics, and more generally “how they feel playing guitar with these simulations”. The amp is open source1 and can be tested online2, even without a guitar (it comes with an audio player, dry guitar samples and a wave generator that can be used at input). The Web page contains links to the source code repository, tutorial videos and a complete report of the measures we made, with different configurations (various soundcard, operating system, browsers), that is summarized in this paper. Figure 1 shows the current GUI (with optional frequency analyzers and oscilloscopes we used to probe the signal at different stages of the simulation). Our initial goal was to evaluate the limits of the WebAudio API and see if it was possible to design a web based guitar amp simulator that could compete with native simulations.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Buffa, Michel and Lebrun, J{\\'{e}}r{\\^{o}}me","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/26.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"1--9","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Real time tube guitar amplifier simulation using WebAudio}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]},{"type":"inproceedings","id":"2017_18","properties":{"abstract":{"value":"A methodology for deploying interactive machine learning and audio tools written in C++ across a wide variety of platforms, including web browsers, is described. The work flow involves development of the code base in C++, making use of all the facilities available to C++ programmers, then transpiling to asm.js bytecode, using Emscripten to allow use of the libraries in web browsers. Audio capabilities are provided via the C++ Maximilian library that is transpiled and connected to the Web Audio API, via the ScriptProcessorNode. Machine learning is provided via the RapidLib library which implements neural networks, k-NN and Dynamic Time Warping for regression and classification tasks. An online, browser-based IDE is the final part of the system, making the toolkit available for education and rapid prototyping purposes, without requiring software other than a web browser. Two example use cases are described: rapid prototyping of novel, electronic instruments and education. Finally, an evaluation of the performance of the libraries is presented, showing that they perform acceptably well in the web browser, compared to the native counterparts but there is room for improvement here. The system is being used by thousands of students in our on-campus and online courses.","brace":"curly"},"address":{"value":"London","brace":"curly"},"author":{"value":"Zbyszy{\\'{n}}ski, Michael and Grierson, Mick and Yee-king, Matthew and Fedden, Leon","brace":"curly"},"booktitle":{"value":"Proceedings of the International Web Audio Conference","brace":"curly"},"editor":{"value":"Thalmann, Florian and Ewert, Sebastian","brace":"curly"},"file":{"value":":Users/Hjem/Documents/WAC Papers/2017/18.pdf:pdf","brace":"curly"},"month":{"value":"aug","brace":"curly"},"pages":{"value":"1--5","brace":"curly"},"publisher":{"value":"Queen Mary University of London","brace":"curly"},"series":{"value":"WAC '17","brace":"curly"},"title":{"value":"{Write once run anywhere revisited: machine learning and audio tools in the browser with C++ and emscripten}","brace":"curly"},"type":{"value":"Paper","brace":"curly"},"url":{"value":"http://qmro.qmul.ac.uk/xmlui/handle/123456789/26127","brace":"curly"},"year":{"value":"2017","brace":"curly"}},"comments":[]}],"commentsAfter":[]}