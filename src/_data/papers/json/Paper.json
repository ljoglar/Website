[{"Media":"https://youtu.be/i1OiPt_roeo","Paper ID":"4","Paper Title":"Facilitating Team-Based Programming Learning with Web Audio","Abstract":"In this paper, we present a course of audio programming using web audio technologies addressed to an interdisciplinary group of master students who are mostly novices in programming. This course is held in two connected university campuses through a portal space and the students are expected to work in cross-campus teams. The course promotes both individual and group work and is based on ideas from science, technology, engineering, arts and mathematics (STEAM) education, team-based learning (TBL) and project-based learning. We show the outcomes of this course, discuss the students' feedback and reflect on the results. We found that it is important to provide individual vs. group work, to use the same code editor for consistent follow-up and to be able to share the screen to solve individual questions. Other aspects inherent to the master (e.g. intensity of the courses, coding in a research-oriented program) and to prior knowledge (e.g. web technologies) should be reconsidered. We conclude with a wider reflection on the challenges and potentials of using web audio as a programming environment for novices in TBL cross-campus courses and how to foster effective novices.","Author Names":"Anna Xambó (De Montfort University)*; Robin Støckert (Norwegian University of Science and Technology); Alexander Refsum Jensenius (University of Oslo); Sigurd Saue ()","Track Name":"Paper","Files":"WAC-2019.pdf (462685 bytes)","Pages":"2--7"},{"Media":"https://youtu.be/VLNVgo8Dq-E","Paper ID":"8","Paper Title":"The application of Networked Music Performance technology to access ensemble activity for socially isolated musicians","Abstract":"Networked Music Performance (NMP) allows musicians to play together over distances via the internet. For musicians who are socially isolated this is a valuable tool to allow musical connections despite barriers of geography or mobility. There are, however, challenges when using this technology, including how musicians cope with technical challenges (such as latency, and setting up and using NMP software), but also the challenges of communicating via potentially degraded audio and video links. By examining current research and a case study of the use of NMP at the University of the Highlands and Islands in a remote part of the UK, this paper argues that these challenges are not insurmountable. Meaningful musical relationships can be built and maintained using typical domestic equipment, and the network environment gives opportunities for musical creativity that would not be possible in a conventional rehearsal space.","Author Names":"Miriam Iorwerth (University of the Highlands and Islands)*; Don Knox (Glasgow Caledonian University)","Track Name":"Paper","Files":"Revised paper Iorwerth Knox.pdf (227122 bytes)","Pages":"8--13"},{"Media":"https://youtu.be/4ZdOdbysd9c","Paper ID":"12","Paper Title":"Sounds Aware: A Mobile App for Raising Awareness of Environmental Sound","Abstract":"Sounds Aware is a web application that runs on a smartphone and uses machine learning to detect human-made sound (anthrophony) and masks it with ambient music as a user walks around their environment. A study was completed to determine if this app is an effective means of shifting a user's attention away from anthrophony and to biological (biophony) and geophysical (geophony) sounds while walking and encouraging environmental awareness. Though the model is pre-trained with the author's local environmental sounds, the user can train the model further on their unique soundscape so that each user gets a personalized experience. After the training process, the user can listen to ambient music based on traits of the surrounding anthrophony. If the app senses less anthrophony and more biophony or geophony, then the music fades away, bringing the user's attention to the anthrophony.","Author Names":"Tate Carson (Louisiana State University)*","Track Name":"Paper","Files":"WAC_2019___Paper_CameraReady.pdf (260644 bytes)","Pages":"14--18"},{"Media":"https://youtu.be/_JiRgQctDWE","Paper ID":"14","Paper Title":"Composing Spatial Music with Web Audio and WebVR","Abstract":"Composers have been exploring complex spatialization techniques within multi-channel sound fields since the earliest days of electroacoustic and electronic music. However the reproduction of such works outside of highly specified concert halls and academic research facilities, or even their accurate reproduction within those spaces, is difficult and unpredictable at best. Tools such as Omnitone combine the reach and simplicity of web browsers with the flexibility and power of higher-order ambisonics (HOA) and binaural rendering, ensuring greater accessibility for existing spatial electronic musical works as well as acting as a platform upon which future works for virtual sound fields can be implemented. This paper describes the technical design and artistic conception of one such spatial composition for binaural listening and immersive visuals on the web - “od” - produced in the CRAIVE-Lab, an immersive audio-visual facility.","Author Names":"Cem Çakmak (Rensselaer Polytechnic Institute)*; Rob Hamilton (Rensselaer Polytechnic Institute)","Track Name":"Paper","Files":"WAC_2019_reup.pdf (7802332 bytes)","Pages":"19-23"},{"Media":"https://youtu.be/Fd_4rtxbNag","Paper ID":"16","Paper Title":"From the museum to the browser: Translating a music-driven  exhibit from physical space to a web app","Abstract":"This paper describes the process of developing a browser-based version of GrooveMachine, a tangible museum exhibit that aims to foster interest in computer science (CS) through the music-driven exploration of a computational system. GrooveMachine is aimed at kids aged 10-14, and specifically targets learners from from groups currently under-represented in computing by demonstrating CS applications that challenge stereotypes. While an observational study suggests that GrooveMachine triggers situational interest, long-term engagement with CS requires this interest to be deepened and developed. To provide an opportunity for interest development, we have implemented a browser-based GrooveMachine. This not only offers the opportunity for learners to continue their exploration of CS through creative interaction, but provides a pathway to other music and CS learning platforms where they can deepen this interest. In this paper we describe the theoretical underpinnings of interest, how it relates to CS, and how it intersects with identity. We also describe the differences between the museum and browser contexts. We detail the design and implementation of GrooveMachine in the museum and explain how we translated it to the browser, including the rationale behind our central design decisions and a discussion of our technical implementation. In this way we provide valuable insight for researchers who want to reach larger audiences by developing browser-based versions of physical installations.","Author Names":"S. M. Astrid Bin (Ableton AG, DE)*; Christina Bui (Georgia Institute of Technology); Benjamin Genchel (Georgia Institute of Technology); Kaushal Sali (Georgia Institute of Technology); Brian Magerko (Georgia Institute of Technology); Jason Freeman (Georgia Institute of Technology)","Track Name":"Paper","Files":"WAC_2019_FINAL.pdf (1614542 bytes)","Pages":"24--29"},{"Media":"https://youtu.be/v5RnOQleS0A","Paper ID":"22","Paper Title":"Join my party! How can we enhance social interactions in music streaming?","Abstract":"In this paper we examine ways to encourage social interactions in online music streaming platforms and discuss the challenges that emerge when deploying  browser-based music mixing systems. With the example of an interactive online application, that allows users to choose music collaboratively based on mood, create their own personal parties, as well as share their favourite tracks with other participants, we explore new alternatives for musical experiences in the context of social media on the one hand and music streaming on the other.","Author Names":"Alo Allik (Queen Mary University of London)*; Florian Thalmann (Queen Mary University of London); Cornelia Metzig (Queen Mary University of London)","Track Name":"Paper","Files":"wac2019_join_the_party.pdf (3067134 bytes)","Pages":"30--34"},{"Media":"https://youtu.be/SivuZcmjRL8","Paper ID":"24","Paper Title":"iMuSciCA: A Web Platform for Science Education Through Music Activities","Abstract":"In this paper we present the iMuSciCA web platform which addresses secondary school students with the aim to support mastery of core academic content on STEM subjects (Physics, Geometry, Mathematics,and Technology) alongside with the development of creativity and deeper learning skills through the students' engagement in music activities. Herein we focus on the technical implementation of the various music related tools and Activity Environments hosted by the iMuSciCA workbench, which are exclusively developed with modern web technologies.","Author Names":"Kosmas Kritsis (Athena Research Center)*; Manuel Bouillon (University of Fribourg); Daniel  Martín-Albo  (Wiris); Carlos Acosta (Leopoly); Robert Piechaud (); Vassilis Katsouros (Athena Research Center)","Track Name":"Paper","Files":"WAC2019_Camera_Ready_B.pdf (3263095 bytes)","Pages":"35--40"},{"Media":"https://youtu.be/1Oirap9_xMg","Paper ID":"26","Paper Title":"QuaverSeries: A Live Coding Environment for Music Performance Using Web Technologies","Abstract":"QuaverSeries consists of a domain-specific language and a single-page web application for collaborative live coding in music performances. Its domain-specific language borrows principles from both programming and digital interface design in its syntax rules, and hence adopts the paradigm of functional programming. The collaborative environment features the concept of 'virtual rooms', in which performers can collaborate from different locations, and the audience can watch the collaboration at the same time. Not only is the code synchronised among all the performers and online audience connected to the server, but the code executing command is also broadcast. This communication strategy, achieved by the integration of the language design and the environment design, provides a new form of interaction for web-based live coding performances.","Author Names":"Qichao Lan (University of Oslo)*; Alexander Refsum Jensenius (University of Oslo)","Track Name":"Paper","Files":"QuaverSeries.pdf (786041 bytes)","Pages":"41--46"},{"Media":"https://youtu.be/YPmq9xFK0vA","Paper ID":"29","Paper Title":"MAIA Util: An NPM Package for Bridging Web Audio with Music-theoretic Concepts","Abstract":"The Web Audio API and associated JavaScript packages have enabled developers to design interfaces where, to an unprecedented extent, the elements of music are at users' fingertips. When these interfaces are intended to help users to understand those musical elements, it can be useful to calculate or display manifestations of music-theoretic concepts, such as the key of an excerpt, the segmentation and labeling of chords, and melodic and harmonic intervals.The MAIA Util package contains JavaScript code for executing these calculations. The input music representations are assumed to be symbolic, coming from MIDI or MusicXML files, or having been estimated from audio. This paper introduces the contents of the package and the music-cognitive research on which some of the constituent algorithms are based.Some of the methods are of a more basic nature, such as for cyclic permutation of numeric arrays or estimation of the pitch and octave of a note given its MIDI number and surrounding context. We have found use for these methods often enough during music interface development that they are included too.The MAIA Util package is available for use from https://www.npmjs.com/package/maia-util","Author Names":"Tom Collins (University of York: MAIA, Inc.)*; Christian Coulon (Music Artificial Intelligence Algorithms, Inc.)","Track Name":"Paper","Files":"sig-alternate-sample.pdf (278444 bytes)","Pages":"47--52"},{"Media":"https://youtu.be/OPwnIRpihjw","Paper ID":"30","Paper Title":"Combining Collaborative and Content Filtering in a Recommendation System for a Web-based DAW","Abstract":"EarSketch is a web-based audio production and education platform that uses an online coding environment and the Web Audio API to teach introductory programming and music production to students. One of the main challenges of implementing an educational online music production platform is providing users with a variety of foundational audio loops to use in order to foster creative personal expression. EarSketch aims to achieve this through the inclusion of a sound browser for users to navigate and select sounds to use as part of their compositions. This paper describes the implementation and evaluation of a hybrid recommendation engine, combining collaborative and content filtering, designed to guide users through the sound browser and promote diversity in student compositions. The paper also presents a preliminary analysis of the impact of different recommendation strategies on user sound selection, and how the application of recommendation strategies can inform the design of EarSketch and other web-based DAWs.","Author Names":"Jason Smith (Georgia Institute of Technology)*; Mikhail Jacob (Georgia Institute of Technology); Jason Freeman (Georgia Institute of Technology); Brian Magerko (Georgia Institute of Technology); Tom Mcklin (The Findings Group)","Track Name":"Paper","Files":"ES_CAI_WAC_2019-3.pdf (635936 bytes)","Pages":"53--58"},{"Media":"https://youtu.be/I7lMTjAupvM","Paper ID":"33","Paper Title":"Design of a real-time multiparty DAW collaboration application using Web MIDI and WebRTC APIs","Abstract":"Collaborative music production in online environments has seen a renewed focus as developers of Digital Audio Workstation (DAW) software include features that cater to limited synchronous participation and multiparty asynchronous collaboration. A significant restriction of these collaboration platforms is the inability for multiple collaborators to effectively communicate and seamlessly work on a high-fidelity audio project in real-time. This paper outlines the design of a browser-based application that enables real-time collaboration between multiple remote instantiations of an established, mainstream and fully-featured DAW platform over the Internet. The proposed application provides access to, and modification and creation of, high-fidelity audio assets, real-time videoconferencing and control data streaming for communication and synchronised DAW operations through Web Real-Time Communication (WebRTC) and Web MIDI Application Programming Interfaces (APIs). The paper reports on a proof-of-concept implementation and results, including several areas for further research and development.","Author Names":"Scott Stickland (The University of Newcastle, Australia)*; Rukshan  Athauda (The University of Newcastle, Australia); Nathan Scott (The University of Newcastle, Australia)","Track Name":"Paper","Files":"Design of a real-time multiparty DAW Collaboration Application using Web MIDI and WebRTC APIs Final.pdf (619761 bytes)","Pages":"59--64"},{"Media":"https://youtu.be/ksXq0zK-FCA","Paper ID":"35","Paper Title":"Soundworks - A Framework for Networked Music Systems on the Web - State of Affairs and New Developments","Abstract":"This paper presents a novel major version of soundworks, a framework dedicated at developing distributed multimedia applications on the web and entirely written in javascript. Since its first release in 2015, the framework has served as a basis for numerous artistic and research projects such as concerts, installations, workshops, teaching or experimental setups. These diverse use cases and situations permitted to validate numerous aspects of the framework but also showed some limitations—particularly in terms of inclusion of non-expert developers such as artists and researchers—leading to the novel version presented here.The paper first presents some applications developed in the last year and show that, despite their idiosyncrasies, recurring problems have emerged during their elaboration and development (e.g. state-management). Second, we present new design and implementation aspects of the framework developed to overcome these issues. Finally we describe a simple testbed application—designed to summarize a number of recurring features and constraints encountered in Network Music Systems—and some elements of its implementation within soundworks.We believe that this novel version will provide solid foundations for the design and implementation of higher-level tools dedicated to non-expert developers, and thereby, foster new artistic, techno- logical and epistemic areas. The soundworks framework is open-source and released under BSD-3-Clause license.","Author Names":"Benjamin Matuszewski (Ircam)*","Track Name":"Paper","Files":"wac2019-matuszewski-soundworks-camera-ready.pdf (1586367 bytes)","Pages":"65--70"},{"Media":"https://youtu.be/oni24HZUYGI","Paper ID":"38","Paper Title":"FAUST online IDE: dynamically compile and publish FAUST code as WebAudio Plugins","Abstract":"Developing or porting existing audio and MIDI effects or instruments for the Web platform is a hot topic. Several initiatives, like business enterprise based ones (Propellerhead recently presented its Rack Extension running on the Web1), to more community based open-source projects are emerging. All of them aim to facilitate porting existing code base (usually developed in native languages like C/C++) as well as facilitating the use of existing audio DSP languages and platforms.We present a solution based around the FAUST DSP audio language, its redesigned Web based editor, and the integration of a plugin GUI editor allowing to directly test, generate and deploy WebAudio Plugins (WAP). This recently proposed plugin format aims to facilitate the integration of pure native WebAudio based components, some ported from native languages like C/C++, as well as plugins written in audio DSP Domain Specific Languages. The paper will describe the complete workflow, from the Faust DSP source written and tested in a fully functional editor to a self-contained plugin running in a separate host application.","Author Names":"Stéphane  Letz (GRAME)*; Shihong Ren (GRAME); Yann Orlarey (GRAME); Romain Michon (Grame: Centre National de Création Musicale); Dominique Fober (GRAME); ElMehdi Aamari (I3S); Michel Buffa (Université Côte d’Azur, CNRS, INRIA); Jerome Lebrun (CNRS)","Track Name":"Paper","Files":"WAC 2019 FAUST online IDE style WAC (1).pdf (1751956 bytes)","Pages":"71--76"},{"Media":"https://youtu.be/EX02cU592vo","Paper ID":"40","Paper Title":"An AudioWorklet-based Signal Engine for a Live Coding Language Ecosystem","Abstract":"This paper reports on early advances in the design of an ecosystem for creating new live coding languages, optimal for audio synthesis, machine learning and machine listening. We present the design rationale and challenges when applying the Web Audio API, and in particular, an AudioWorklet-based solution to refactoring our digital signal processing library Maximilian.js for our high-performance signal synthesis engine. Furthermore, we contribute with a new system implementation, engineered for modern web applications, and for the live coding community to design their own idiosyncratic languages and interfaces applying our signal engine. The evaluation shows that the system runs with high reliability, efficiency and low latency.","Author Names":"Francisco Bernardo (University of Sussex)*; Chris Kiefer (University of Sussex); Thor Magnusson (Music Department, University of Sussex)","Track Name":"Paper","Files":"WAC_2019_FB_CK_TM_camera-ready.pdf (1298990 bytes)","Pages":"77--82"},{"Media":"https://youtu.be/Xhc4L8ukSEw","Paper ID":"43","Paper Title":"Interference: Adapting Player-Music Interaction in Games to a Live Performance Context","Abstract":"Interference is a multiplayer music game and generative music system, which is implemented as a Javascript web application and designed for live performance. It is based on the potential for dynamic music generation that exists in video games through player-music interaction. It uses a competitive multiplayer form to sustain a feedback loop in which players construct and change the music at a fine scale, while the music in turn informs players of the game state, affecting how they continue to play and therefore change the music. The design of Interference must also manage conflicts between games and music as contrasting media, such as presentation, length, and complexity, in order to create both a game that is engaging for its players and a musical performance that is compelling to its audience. Towards this objective, it combines elements of games that do not traditionally exist in music, such as an explicit goal-oriented structure, with features that serve strictly musical, performative purposes, allowing players to act simultaneously as performers. To support this design, it utilizes several existing web technologies to achieve tight synchronization, changeable sound synthesis, and networked interaction between players.","Author Names":"Matthew Wang (Princeton University)*","Track Name":"Paper","Files":"WAC2019_MatthewWang.pdf (1250323 bytes)","Pages":"83--86"},{"Media":"https://youtu.be/iY5CU--TIfA","Paper ID":"44","Paper Title":"Towards Large-Scale Artistic Practice with Web Technologies","Abstract":"In this article, we present a software architecture that explores the technological potential of the web as a programmable interface and as an interpersonal connection point in the artistic practice. This structure exposes the recently proposed Akson audio-visual (AV) environment, also raising a technical evaluation of the technologies and design used to allow the development of both the platform and the network.","Author Names":"Luis Arandas (Braga Media Arts)*; José Gomes (Portuguese Catholic University CITAR School of Arts: Braga Media Arts); Rui Penha ()","Track Name":"Paper","Files":"towards.pdf (2837783 bytes)","Pages":"87--91"},{"Media":"https://youtu.be/4uhqIf0nshQ","Paper ID":"47","Paper Title":"Csound Web-IDE","Abstract":"Csound Web-IDE is an open-source, browser-based integrated development environment (IDE) for sound and music computing using Csound. The web application offers users the ability to edit and run standard, multi-file Csound projects in the same way they would do on the desktop, mobile, and embedded platforms. Enabled by modern web technologies, envisioned use cases for the Web-IDE include computer music education, music composition, and development of realtime interactive systems, as well future integration with other WebAudio-based systems.","Author Names":"Steven Yi (Rochester Institute of Technology)*; Hlöðver  Sigurðsson (Independent); Edward Costello (Maynooth University)","Track Name":"Paper","Files":"wac2019_csound_web_ide.pdf (614451 bytes)","Pages":"92--97"},{"Media":"https://youtu.be/FIptSmvA4Vo","Paper ID":"49","Paper Title":"Bringing the TidalCycles Mini-Language to the Web","Abstract":"TidalCycles has rapidly become the most popular system for many styles of live coding performance, in particular Algoraves. We created a JavaScript dialect of its mini-notation for pattern, enabling easy integration with creative coding tools. Our research pairs a formalism describing the mini-notation with a small JavaScript library for generating events over time; this library is suitable for generating events inside of an AudioWorkletProcessor thread and for assisting with scheduling in JavaScript environments more generally. We describe integrating the library into the two live coding systems, Gibber and Hydra, and discuss an accompanying technique for visually annotating the playback of TidalCycles patterns over time.","Author Names":"Charlie Roberts (Worcester Polytechnic Institute)*; Mariana Pachón-Puentes (Worcester Polytechnic Institute)","Track Name":"Paper","Files":"Bringing_the_TidalCycles_Mini_Language_to_the_Browser-4.pdf (549225 bytes)","Pages":"98--102"},{"Media":"https://youtu.be/WctKn3cq-Yw","Paper ID":"58","Paper Title":"Responsive Space. Liveness through spatial distribution of sound and image.","Abstract":"In this project a performance framework called \"Responsive Space\" has been created, which allows a flexible way of working with distributed sound and image projections. The system consists of a multichannel speaker-system, up to three video projections, a local Wifi network with a connected webserver and mobile devices. The audience is invited to log into the local network with their mobile devices. In the browser of the mobile devices sound and image is generated or streamed.This offers the possibility of a great diversity in the spatial distribution of sound and image. As experienced in previous projects with live audio-streaming and mobile devices the spatial gesture of music as a musical parameter comes to the fore. In the performances the audio is streamed with an icecast-server and visual output is generated with javascript on the client’s browser. The imperfection of time synchronization leads to very interesting effects. The awareness of space and the interaction of the audience with each other leads to the emergence of a social space in the concert.In addition to the dimension of space this setup also examines the relationship between different media layers. This is central for the question how to achieve \"liveness\" - which in my opinion can also be achieved with this spatial arrangement and distribution of sound and image.","Author Names":"Raimund Vogtenhuber (University of Arts Zurich / ICST)*","Track Name":"Paper","Files":"Responsive Space – Liveness through spatial distribution of sound and image.pdf (1329943 bytes)","Pages":"103--107"},{"Media":"","Paper ID":"","Paper Title":"","Abstract":"","Author Names":"","Track Name":"","Files":"","Pages":""}]